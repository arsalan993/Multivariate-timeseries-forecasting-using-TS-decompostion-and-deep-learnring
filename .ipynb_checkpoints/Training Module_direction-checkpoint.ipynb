{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stldecompose import decompose\n",
    "from matplotlib import pyplot\n",
    "from keras.models import model_from_json\n",
    "#https://stackoverflow.com/questions/48356464/how-to-model-convolutional-recurrent-network-crnn-in-keras\n",
    "#https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/\n",
    "#https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras\n",
    "#https://github.com/keras-team/keras/issues/6063\n",
    "#https://stackoverflow.com/questions/34357617/append-2d-array-to-3d-array-extending-third-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(a, window, step_size):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window +2  - step_size, window)\n",
    "    strides = a.strides + (a.strides[-1] * step_size,)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_win = 15\n",
    "out_win = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMC Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_bt = pd.read_csv(\"cmc_btc.csv\")\n",
    "# data_bt['Date'] = pd.to_datetime(data_bt['Date'])\n",
    "# data_bt = data_bt.sort_values(by=['Date']).reset_index(drop=True)\n",
    "# data_bt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_col = pd.to_datetime(data_bt[\"Date\"])\n",
    "# data_open = data_bt[\"Open*\"]\n",
    "# data_high = data_bt[\"High\"]\n",
    "# data_low = data_bt[\"Low\"]\n",
    "# data_close = data_bt[\"Close**\"]\n",
    "# data_vol = data_bt[\"Volume\"]\n",
    "# data_mark = data_bt[\"Market Cap\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BITFINEX DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_open</th>\n",
       "      <th>price_high</th>\n",
       "      <th>price_low</th>\n",
       "      <th>price_close</th>\n",
       "      <th>volume_traded</th>\n",
       "      <th>trades_count</th>\n",
       "      <th>time_close</th>\n",
       "      <th>time_open</th>\n",
       "      <th>time_period_start</th>\n",
       "      <th>time_period_end</th>\n",
       "      <th>market_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.250000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>93.03000</td>\n",
       "      <td>93.100010</td>\n",
       "      <td>390.827224</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-03-31 23:36:44</td>\n",
       "      <td>2013-03-31T22:07:48.0000000Z</td>\n",
       "      <td>2013-03-31T22:00:00.000000Z</td>\n",
       "      <td>2013-04-01T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.170000</td>\n",
       "      <td>105.900000</td>\n",
       "      <td>92.49999</td>\n",
       "      <td>102.370000</td>\n",
       "      <td>4919.654127</td>\n",
       "      <td>627</td>\n",
       "      <td>2013-04-01 23:41:42</td>\n",
       "      <td>2013-04-01T00:05:39.0000000Z</td>\n",
       "      <td>2013-04-01T00:00:00.000000Z</td>\n",
       "      <td>2013-04-02T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.800000</td>\n",
       "      <td>118.388067</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>117.989990</td>\n",
       "      <td>9084.832816</td>\n",
       "      <td>1205</td>\n",
       "      <td>2013-04-02 23:54:35</td>\n",
       "      <td>2013-04-02T00:00:11.0000000Z</td>\n",
       "      <td>2013-04-02T00:00:00.000000Z</td>\n",
       "      <td>2013-04-03T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.579097</td>\n",
       "      <td>146.880000</td>\n",
       "      <td>101.51088</td>\n",
       "      <td>134.952969</td>\n",
       "      <td>12909.402178</td>\n",
       "      <td>2502</td>\n",
       "      <td>2013-04-03 23:59:37</td>\n",
       "      <td>2013-04-03T00:07:29.0000000Z</td>\n",
       "      <td>2013-04-03T00:00:00.000000Z</td>\n",
       "      <td>2013-04-04T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131.779686</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>119.00000</td>\n",
       "      <td>132.681000</td>\n",
       "      <td>6910.100414</td>\n",
       "      <td>1456</td>\n",
       "      <td>2013-04-04 23:50:09</td>\n",
       "      <td>2013-04-04T00:02:15.0000000Z</td>\n",
       "      <td>2013-04-04T00:00:00.000000Z</td>\n",
       "      <td>2013-04-05T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price_open  price_high  price_low  price_close  volume_traded  \\\n",
       "0   93.250000  100.000000   93.03000    93.100010     390.827224   \n",
       "1   93.170000  105.900000   92.49999   102.370000    4919.654127   \n",
       "2  102.800000  118.388067   99.00000   117.989990    9084.832816   \n",
       "3  116.579097  146.880000  101.51088   134.952969   12909.402178   \n",
       "4  131.779686  143.000000  119.00000   132.681000    6910.100414   \n",
       "\n",
       "   trades_count          time_close                     time_open  \\\n",
       "0            55 2013-03-31 23:36:44  2013-03-31T22:07:48.0000000Z   \n",
       "1           627 2013-04-01 23:41:42  2013-04-01T00:05:39.0000000Z   \n",
       "2          1205 2013-04-02 23:54:35  2013-04-02T00:00:11.0000000Z   \n",
       "3          2502 2013-04-03 23:59:37  2013-04-03T00:07:29.0000000Z   \n",
       "4          1456 2013-04-04 23:50:09  2013-04-04T00:02:15.0000000Z   \n",
       "\n",
       "             time_period_start               time_period_end  market_cap  \n",
       "0  2013-03-31T22:00:00.000000Z  2013-04-01T00:00:00.0000000Z         NaN  \n",
       "1  2013-04-01T00:00:00.000000Z  2013-04-02T00:00:00.0000000Z         NaN  \n",
       "2  2013-04-02T00:00:00.000000Z  2013-04-03T00:00:00.0000000Z         NaN  \n",
       "3  2013-04-03T00:00:00.000000Z  2013-04-04T00:00:00.0000000Z         NaN  \n",
       "4  2013-04-04T00:00:00.000000Z  2013-04-05T00:00:00.0000000Z         NaN  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bt = pd.read_csv(\"BITFINEX_SPOT_BTC_USD/1DAY_2013-03-31&2018-09-20.csv\")\n",
    "data_bt['time_close'] = pd.to_datetime(data_bt['time_close'])\n",
    "data_bt = data_bt.sort_values(by=['time_close']).reset_index(drop=True)\n",
    "data_bt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_open           False\n",
       "price_high           False\n",
       "price_low            False\n",
       "price_close          False\n",
       "volume_traded        False\n",
       "trades_count         False\n",
       "time_close           False\n",
       "time_open            False\n",
       "time_period_start    False\n",
       "time_period_end      False\n",
       "market_cap           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bt.dropna(inplace=True)\n",
    "data_bt.reset_index(drop=True, inplace=True)\n",
    "data_bt.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = pd.to_datetime(data_bt[\"time_close\"])\n",
    "data_open = data_bt[\"price_open\"]\n",
    "data_high = data_bt[\"price_high\"]\n",
    "data_low = data_bt[\"price_low\"]\n",
    "data_close = data_bt[\"price_close\"]\n",
    "data_vol = data_bt[\"volume_traded\"]\n",
    "data_mark = data_bt[\"market_cap\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_open = np.log(data_open)\n",
    "log_high = np.log(data_high)\n",
    "log_low = np.log(data_low)\n",
    "log_close = np.log(data_close)\n",
    "log_vol = np.log(data_vol)\n",
    "log_mark = np.log(data_mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STL Decompostion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_open = pd.DataFrame(log_open)\n",
    "log_open = log_open.set_index(date_col)\n",
    "\n",
    "log_high = pd.DataFrame(log_high)\n",
    "log_high = log_high.set_index(date_col)\n",
    "\n",
    "log_low = pd.DataFrame(log_low)\n",
    "log_low = log_low.set_index(date_col)\n",
    "\n",
    "log_close = pd.DataFrame(log_close)\n",
    "log_close = log_close.set_index(date_col)\n",
    "\n",
    "log_vol = pd.DataFrame(log_vol)\n",
    "log_vol = log_vol.set_index(date_col)\n",
    "\n",
    "log_mark = pd.DataFrame(log_mark)\n",
    "log_mark = log_mark.set_index(date_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "stl_open = decompose(log_open)\n",
    "stl_high = decompose(log_high)\n",
    "stl_low = decompose(log_low)\n",
    "stl_close = decompose(log_close)\n",
    "stl_vol = decompose(log_vol)\n",
    "stl_mark = decompose(log_mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deasonal TS component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "deseason_open  = (stl_open.resid + stl_open.trend).iloc[:,0]\n",
    "deseason_high  = (stl_high.resid + stl_high.trend).iloc[:,0]\n",
    "deseason_low   = (stl_low.resid + stl_low.trend).iloc[:,0]\n",
    "deseason_close = (stl_close.resid + stl_close.trend).iloc[:,0]\n",
    "deseason_vol   = (stl_vol.resid + stl_vol.trend).iloc[:,0]\n",
    "deseason_mark  = (stl_mark.resid + stl_mark.trend).iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Normalized Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: Series.strides is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "date_col_win_in = rolling_window(date_col[0:(len(data_bt)-out_win)], in_win, 1)\n",
    "date_col_win_in_exp = np.expand_dims(date_col_win_in, axis=2)\n",
    "\n",
    "data_open_win_in = rolling_window(deseason_open[0:(len(deseason_open)-out_win)], in_win, 1)\n",
    "data_open_win_in = pd.DataFrame(data_open_win_in) \n",
    "norm_open_win_in = data_open_win_in.subtract(data_open_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_open_win_in_exp = np.expand_dims(norm_open_win_in.values, axis=2)\n",
    "\n",
    "data_high_win_in = rolling_window(deseason_high[0:(len(deseason_high)-out_win)], in_win, 1)\n",
    "data_high_win_in = pd.DataFrame(data_high_win_in) \n",
    "norm_high_win_in = data_high_win_in.subtract(data_high_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_high_win_in_exp = np.expand_dims(norm_high_win_in.values, axis=2)\n",
    "\n",
    "data_low_win_in = rolling_window(deseason_low[0:(len(deseason_low)-out_win)], in_win, 1)\n",
    "data_low_win_in = pd.DataFrame(data_low_win_in) \n",
    "norm_low_win_in = data_low_win_in.subtract(data_low_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_low_win_in_exp = np.expand_dims(norm_low_win_in.values, axis=2)\n",
    "\n",
    "data_close_win_in = rolling_window(deseason_close[0:(len(deseason_close)-out_win)], in_win, 1)\n",
    "data_close_win_in = pd.DataFrame(data_close_win_in) \n",
    "norm_close_win_in = data_close_win_in.subtract(data_close_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_close_win_in_exp = np.expand_dims(norm_close_win_in.values, axis=2)\n",
    "\n",
    "data_vol_win_in = rolling_window(deseason_vol[0:(len(deseason_vol)-out_win)], in_win, 1)\n",
    "data_vol_win_in = pd.DataFrame(data_vol_win_in) \n",
    "norm_vol_win_in = data_vol_win_in.subtract(data_vol_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_vol_win_in_exp = np.expand_dims(norm_vol_win_in.values, axis=2)\n",
    "\n",
    "data_mark_win_in = rolling_window(deseason_mark[0:(len(deseason_mark)-out_win)], in_win, 1)\n",
    "data_mark_win_in = pd.DataFrame(data_mark_win_in) \n",
    "norm_mark_win_in = data_mark_win_in.subtract(data_mark_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_mark_win_in_exp = np.expand_dims(norm_mark_win_in.values, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orignal Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: Series.strides is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "date_col_win_all = rolling_window(date_col[0:(len(data_bt)-out_win)], in_win, 1)\n",
    "date_col_win_all = pd.DataFrame(date_col_win_all)\n",
    "\n",
    "data_open_win_all = rolling_window(data_open[0:(len(data_open)-out_win)], in_win, 1)\n",
    "data_open_win_all = pd.DataFrame(data_open_win_all) \n",
    "\n",
    "data_high_win_all = rolling_window(data_high[0:(len(data_high)-out_win)], in_win, 1)\n",
    "data_high_win_all = pd.DataFrame(data_high_win_all) \n",
    "\n",
    "\n",
    "data_low_win_all = rolling_window(data_low[0:(len(data_low)-out_win)], in_win, 1)\n",
    "data_low_win_all = pd.DataFrame(data_low_win_all) \n",
    "\n",
    "\n",
    "data_close_win_all = rolling_window(data_close[0:(len(data_close)-out_win)], in_win, 1)\n",
    "data_close_win_all = pd.DataFrame(data_close_win_all) \n",
    "\n",
    "\n",
    "data_vol_win_all = rolling_window(data_vol[0:(len(data_vol)-out_win)], in_win, 1)\n",
    "data_vol_win_all = pd.DataFrame(data_vol_win_all) \n",
    "\n",
    "\n",
    "data_mark_win_all = rolling_window(data_mark[0:(len(data_mark)-out_win)], in_win, 1)\n",
    "data_mark_win_all = pd.DataFrame(data_mark_win_all) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels :-   \"Up : 1\"   &   \"Down : 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "\n",
    "for i in range(1,len(data_close_win_all)):\n",
    "    if (data_close_win_all.iloc[i,][in_win-1] > data_close_win_all.iloc[i-1,][in_win-1]):\n",
    "        true_labels.append(1)\n",
    "    else:\n",
    "        true_labels.append(0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Data for Training in High Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1942, 15, 6)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all = np.dstack((norm_open_win_in_exp, norm_high_win_in_exp, norm_low_win_in_exp\n",
    "                   ,norm_close_win_in_exp, norm_vol_win_in_exp, norm_mark_win_in_exp))\n",
    "x_all = x_all[:len(x_all)-1,:,:]\n",
    "x_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = pd.DataFrame(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  1\n",
       "3  1\n",
       "4  1"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Validation Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352, 15, 6) (1590, 15, 6) 1590 352\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train,  = train_test_split(x_all, y_all, test_size=0.10,shuffle=False)\n",
    "\n",
    "msk = np.random.rand(len(x_all)) < 0.81\n",
    "\n",
    "X_train = x_all[msk]\n",
    "X_test = x_all[~msk]\n",
    "\n",
    "Y_train = y_all[msk]\n",
    "Y_test = y_all[~msk]\n",
    "\n",
    "print(X_test.shape, X_train.shape,len(Y_train),len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Deep Learning Architecture using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import LSTM, RepeatVector, TimeDistributed, Dense, Activation,Permute,Conv1D,GaussianNoise,Dropout,regularizers,Conv2D,Reshape\n",
    "from keras.optimizers import SGD, nadam,adam\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "model = Sequential() \n",
    "model.add(LSTM(256, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences = True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "nadam = nadam(lr = 0.02)\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"nadam\", metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_34 (LSTM)               (None, 15, 256)           269312    \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 474,753\n",
      "Trainable params: 474,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1590 samples, validate on 352 samples\n",
      "Epoch 1/50\n",
      " - 11s - loss: 0.6960 - acc: 0.5157 - val_loss: 0.6924 - val_acc: 0.5227\n",
      "Epoch 2/50\n",
      " - 6s - loss: 0.6923 - acc: 0.5403 - val_loss: 0.6929 - val_acc: 0.5227\n",
      "Epoch 3/50\n",
      " - 7s - loss: 0.6932 - acc: 0.5264 - val_loss: 0.6946 - val_acc: 0.5227\n",
      "Epoch 4/50\n",
      " - 7s - loss: 0.6906 - acc: 0.5371 - val_loss: 0.6927 - val_acc: 0.5227\n",
      "Epoch 5/50\n",
      " - 7s - loss: 0.6894 - acc: 0.5377 - val_loss: 0.6928 - val_acc: 0.5227\n",
      "Epoch 6/50\n",
      " - 7s - loss: 0.6887 - acc: 0.5384 - val_loss: 0.6926 - val_acc: 0.5227\n",
      "Epoch 7/50\n",
      " - 7s - loss: 0.6886 - acc: 0.5428 - val_loss: 0.6921 - val_acc: 0.5256\n",
      "Epoch 8/50\n",
      " - 7s - loss: 0.6877 - acc: 0.5403 - val_loss: 0.6923 - val_acc: 0.5312\n",
      "Epoch 9/50\n",
      " - 7s - loss: 0.6876 - acc: 0.5447 - val_loss: 0.6918 - val_acc: 0.5256\n",
      "Epoch 10/50\n",
      " - 7s - loss: 0.6872 - acc: 0.5503 - val_loss: 0.6924 - val_acc: 0.5256\n",
      "Epoch 11/50\n",
      " - 7s - loss: 0.6869 - acc: 0.5528 - val_loss: 0.6916 - val_acc: 0.5284\n",
      "Epoch 12/50\n",
      " - 7s - loss: 0.6855 - acc: 0.5522 - val_loss: 0.6954 - val_acc: 0.5028\n",
      "Epoch 13/50\n",
      " - 7s - loss: 0.6864 - acc: 0.5440 - val_loss: 0.6949 - val_acc: 0.5057\n",
      "Epoch 14/50\n",
      " - 7s - loss: 0.6858 - acc: 0.5459 - val_loss: 0.6949 - val_acc: 0.5170\n",
      "Epoch 15/50\n",
      " - 7s - loss: 0.6834 - acc: 0.5579 - val_loss: 0.6945 - val_acc: 0.5256\n",
      "Epoch 16/50\n",
      " - 7s - loss: 0.6836 - acc: 0.5560 - val_loss: 0.6941 - val_acc: 0.5170\n",
      "Epoch 17/50\n",
      " - 7s - loss: 0.6831 - acc: 0.5547 - val_loss: 0.6936 - val_acc: 0.5170\n",
      "Epoch 18/50\n",
      " - 7s - loss: 0.6821 - acc: 0.5667 - val_loss: 0.6935 - val_acc: 0.5114\n",
      "Epoch 19/50\n",
      " - 7s - loss: 0.6817 - acc: 0.5585 - val_loss: 0.6935 - val_acc: 0.5114\n",
      "Epoch 20/50\n",
      " - 7s - loss: 0.6820 - acc: 0.5572 - val_loss: 0.6935 - val_acc: 0.5057\n",
      "Epoch 21/50\n",
      " - 7s - loss: 0.6820 - acc: 0.5616 - val_loss: 0.6935 - val_acc: 0.5057\n",
      "Epoch 22/50\n",
      " - 8s - loss: 0.6824 - acc: 0.5616 - val_loss: 0.6935 - val_acc: 0.5057\n",
      "Epoch 23/50\n",
      " - 7s - loss: 0.6821 - acc: 0.5541 - val_loss: 0.6935 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      " - 7s - loss: 0.6814 - acc: 0.5648 - val_loss: 0.6936 - val_acc: 0.5114\n",
      "Epoch 25/50\n",
      " - 6s - loss: 0.6812 - acc: 0.5597 - val_loss: 0.6935 - val_acc: 0.5142\n",
      "Epoch 26/50\n",
      " - 7s - loss: 0.6821 - acc: 0.5579 - val_loss: 0.6936 - val_acc: 0.5114\n",
      "Epoch 27/50\n",
      " - 7s - loss: 0.6813 - acc: 0.5465 - val_loss: 0.6936 - val_acc: 0.5142\n",
      "Epoch 28/50\n",
      " - 7s - loss: 0.6819 - acc: 0.5560 - val_loss: 0.6936 - val_acc: 0.5170\n",
      "Epoch 29/50\n",
      " - 7s - loss: 0.6821 - acc: 0.5616 - val_loss: 0.6936 - val_acc: 0.5199\n",
      "Epoch 30/50\n",
      " - 6s - loss: 0.6823 - acc: 0.5623 - val_loss: 0.6936 - val_acc: 0.5199\n",
      "Epoch 31/50\n",
      " - 7s - loss: 0.6818 - acc: 0.5579 - val_loss: 0.6936 - val_acc: 0.5199\n",
      "Epoch 32/50\n",
      " - 7s - loss: 0.6813 - acc: 0.5503 - val_loss: 0.6937 - val_acc: 0.5170\n",
      "Epoch 33/50\n",
      " - 7s - loss: 0.6819 - acc: 0.5547 - val_loss: 0.6937 - val_acc: 0.5170\n",
      "Epoch 34/50\n",
      " - 7s - loss: 0.6812 - acc: 0.5535 - val_loss: 0.6938 - val_acc: 0.5199\n",
      "Epoch 35/50\n",
      " - 7s - loss: 0.6805 - acc: 0.5553 - val_loss: 0.6939 - val_acc: 0.5170\n",
      "Epoch 36/50\n",
      " - 7s - loss: 0.6820 - acc: 0.5579 - val_loss: 0.6939 - val_acc: 0.5142\n",
      "Epoch 37/50\n",
      " - 7s - loss: 0.6810 - acc: 0.5553 - val_loss: 0.6939 - val_acc: 0.5256\n",
      "Epoch 38/50\n",
      " - 7s - loss: 0.6805 - acc: 0.5579 - val_loss: 0.6940 - val_acc: 0.5256\n",
      "Epoch 39/50\n",
      " - 7s - loss: 0.6811 - acc: 0.5491 - val_loss: 0.6941 - val_acc: 0.5312\n",
      "Epoch 40/50\n",
      " - 7s - loss: 0.6810 - acc: 0.5560 - val_loss: 0.6942 - val_acc: 0.5227\n",
      "Epoch 41/50\n",
      " - 7s - loss: 0.6807 - acc: 0.5522 - val_loss: 0.6943 - val_acc: 0.5312\n",
      "Epoch 42/50\n",
      " - 7s - loss: 0.6807 - acc: 0.5591 - val_loss: 0.6944 - val_acc: 0.5256\n",
      "Epoch 43/50\n",
      " - 7s - loss: 0.6815 - acc: 0.5616 - val_loss: 0.6945 - val_acc: 0.5284\n",
      "Epoch 44/50\n",
      " - 7s - loss: 0.6814 - acc: 0.5553 - val_loss: 0.6946 - val_acc: 0.5227\n",
      "Epoch 45/50\n",
      " - 7s - loss: 0.6806 - acc: 0.5465 - val_loss: 0.6948 - val_acc: 0.5227\n",
      "Epoch 46/50\n",
      " - 7s - loss: 0.6812 - acc: 0.5522 - val_loss: 0.6948 - val_acc: 0.5284\n",
      "Epoch 47/50\n",
      " - 7s - loss: 0.6802 - acc: 0.5528 - val_loss: 0.6948 - val_acc: 0.5256\n",
      "Epoch 48/50\n",
      " - 7s - loss: 0.6810 - acc: 0.5528 - val_loss: 0.6949 - val_acc: 0.5284\n",
      "Epoch 49/50\n",
      " - 7s - loss: 0.6805 - acc: 0.5528 - val_loss: 0.6949 - val_acc: 0.5256\n",
      "Epoch 50/50\n",
      " - 7s - loss: 0.6800 - acc: 0.5566 - val_loss: 0.6950 - val_acc: 0.5284\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',patience=3, min_lr=0.00001,factor=0.1)\n",
    "# for i in range(40):\n",
    "#     model.fit(X_train, Y_train,\n",
    "#               epochs=1,\n",
    "#               batch_size=batch_size,\n",
    "#               verbose=2,\n",
    "#               validation_data = (X_test, Y_test))\n",
    "#     model.reset_states()\n",
    "\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=50,\n",
    "          batch_size=batch_size,\n",
    "          verbose=2,\n",
    "          callbacks=[reduce_lr],\n",
    "          validation_data = (X_test, Y_test))\n",
    "\n",
    "# Save the weights\n",
    "model.save_weights('model_weights.h5')\n",
    "\n",
    "# Save the model architecture\n",
    "with open('model_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model reconstruction from JSON file\n",
    "with open('model_architecture.json', 'r') as f:\n",
    "    model = model_from_json(f.read())\n",
    "\n",
    "# Load weights into the new model\n",
    "model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrying out Prediction on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(0,len(X_test)):\n",
    "    pred = model.predict(X_test[i:(i+1),:,:])\n",
    "    y_pred.append(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renormalizing and seasonalizing the predictions and true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: Series.strides is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "season_high  = pd.DataFrame(rolling_window(stl_high.seasonal.iloc[:,0][in_win:len(stl_high.seasonal)], out_win, 1))\n",
    "season_low   = pd.DataFrame(rolling_window(stl_low.seasonal.iloc[:,0][in_win:len(stl_low.seasonal)], out_win, 1))\n",
    "season_close = pd.DataFrame(rolling_window(stl_close.seasonal.iloc[:,0][in_win:len(stl_close.seasonal)], out_win, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: Series.strides is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "season_high_pr  = pd.DataFrame(rolling_window(stl_high.seasonal.iloc[:,0][0:(len(stl_high.seasonal)-out_win)], in_win, 1))\n",
    "season_high_pr.drop(season_high_pr.columns[0:(in_win-out_win)], axis=1, inplace=True)\n",
    "season_high_pr.columns = np.arange(len(season_high_pr.columns))\n",
    "season_low_pr   = pd.DataFrame(rolling_window(stl_low.seasonal.iloc[:,0][0:(len(stl_low.seasonal)-out_win)], in_win, 1))\n",
    "season_low_pr.drop(season_low_pr.columns[0:(in_win-out_win)], axis=1, inplace=True)\n",
    "season_low_pr.columns = np.arange(len(season_low_pr.columns))\n",
    "season_close_pr = pd.DataFrame(rolling_window(stl_close.seasonal.iloc[:,0][0:(len(stl_close.seasonal)-out_win)], in_win, 1))\n",
    "season_close_pr.drop(season_close_pr.columns[0:(in_win-out_win)], axis=1, inplace=True)\n",
    "season_close_pr.columns = np.arange(len(season_close_pr.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1590"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred < 0.5] = 0\n",
    "y_pred[y_pred >= 0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.51315789, 0.5326087 ]),\n",
       " array([0.23214286, 0.79891304]),\n",
       " array([0.31967213, 0.63913043]),\n",
       " array([168, 184], dtype=int64))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5284090909090909"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Y_test,y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 129, 37, 147)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
