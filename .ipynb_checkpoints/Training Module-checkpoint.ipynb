{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stldecompose import decompose\n",
    "from matplotlib import pyplot\n",
    "from keras.models import model_from_json\n",
    "#https://stackoverflow.com/questions/48356464/how-to-model-convolutional-recurrent-network-crnn-in-keras\n",
    "#https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/\n",
    "#https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras\n",
    "#https://github.com/keras-team/keras/issues/6063\n",
    "#https://stackoverflow.com/questions/34357617/append-2d-array-to-3d-array-extending-third-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(a, window, step_size):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window +2  - step_size, window)\n",
    "    strides = a.strides + (a.strides[-1] * step_size,)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_win = 15\n",
    "out_win = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMC Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_bt = pd.read_csv(\"cmc_btc.csv\")\n",
    "# data_bt['Date'] = pd.to_datetime(data_bt['Date'])\n",
    "# data_bt = data_bt.sort_values(by=['Date']).reset_index(drop=True)\n",
    "# data_bt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_col = pd.to_datetime(data_bt[\"Date\"])\n",
    "# data_open = data_bt[\"Open*\"]\n",
    "# data_high = data_bt[\"High\"]\n",
    "# data_low = data_bt[\"Low\"]\n",
    "# data_close = data_bt[\"Close**\"]\n",
    "# data_vol = data_bt[\"Volume\"]\n",
    "# data_mark = data_bt[\"Market Cap\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BITFINEX DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_open</th>\n",
       "      <th>price_high</th>\n",
       "      <th>price_low</th>\n",
       "      <th>price_close</th>\n",
       "      <th>volume_traded</th>\n",
       "      <th>trades_count</th>\n",
       "      <th>time_close</th>\n",
       "      <th>time_open</th>\n",
       "      <th>time_period_start</th>\n",
       "      <th>time_period_end</th>\n",
       "      <th>market_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.250000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>93.03000</td>\n",
       "      <td>93.100010</td>\n",
       "      <td>390.827224</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-03-31 23:36:44</td>\n",
       "      <td>2013-03-31T22:07:48.0000000Z</td>\n",
       "      <td>2013-03-31T22:00:00.000000Z</td>\n",
       "      <td>2013-04-01T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.170000</td>\n",
       "      <td>105.900000</td>\n",
       "      <td>92.49999</td>\n",
       "      <td>102.370000</td>\n",
       "      <td>4919.654127</td>\n",
       "      <td>627</td>\n",
       "      <td>2013-04-01 23:41:42</td>\n",
       "      <td>2013-04-01T00:05:39.0000000Z</td>\n",
       "      <td>2013-04-01T00:00:00.000000Z</td>\n",
       "      <td>2013-04-02T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.800000</td>\n",
       "      <td>118.388067</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>117.989990</td>\n",
       "      <td>9084.832816</td>\n",
       "      <td>1205</td>\n",
       "      <td>2013-04-02 23:54:35</td>\n",
       "      <td>2013-04-02T00:00:11.0000000Z</td>\n",
       "      <td>2013-04-02T00:00:00.000000Z</td>\n",
       "      <td>2013-04-03T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.579097</td>\n",
       "      <td>146.880000</td>\n",
       "      <td>101.51088</td>\n",
       "      <td>134.952969</td>\n",
       "      <td>12909.402178</td>\n",
       "      <td>2502</td>\n",
       "      <td>2013-04-03 23:59:37</td>\n",
       "      <td>2013-04-03T00:07:29.0000000Z</td>\n",
       "      <td>2013-04-03T00:00:00.000000Z</td>\n",
       "      <td>2013-04-04T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131.779686</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>119.00000</td>\n",
       "      <td>132.681000</td>\n",
       "      <td>6910.100414</td>\n",
       "      <td>1456</td>\n",
       "      <td>2013-04-04 23:50:09</td>\n",
       "      <td>2013-04-04T00:02:15.0000000Z</td>\n",
       "      <td>2013-04-04T00:00:00.000000Z</td>\n",
       "      <td>2013-04-05T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price_open  price_high  price_low  price_close  volume_traded  \\\n",
       "0   93.250000  100.000000   93.03000    93.100010     390.827224   \n",
       "1   93.170000  105.900000   92.49999   102.370000    4919.654127   \n",
       "2  102.800000  118.388067   99.00000   117.989990    9084.832816   \n",
       "3  116.579097  146.880000  101.51088   134.952969   12909.402178   \n",
       "4  131.779686  143.000000  119.00000   132.681000    6910.100414   \n",
       "\n",
       "   trades_count          time_close                     time_open  \\\n",
       "0            55 2013-03-31 23:36:44  2013-03-31T22:07:48.0000000Z   \n",
       "1           627 2013-04-01 23:41:42  2013-04-01T00:05:39.0000000Z   \n",
       "2          1205 2013-04-02 23:54:35  2013-04-02T00:00:11.0000000Z   \n",
       "3          2502 2013-04-03 23:59:37  2013-04-03T00:07:29.0000000Z   \n",
       "4          1456 2013-04-04 23:50:09  2013-04-04T00:02:15.0000000Z   \n",
       "\n",
       "             time_period_start               time_period_end  market_cap  \n",
       "0  2013-03-31T22:00:00.000000Z  2013-04-01T00:00:00.0000000Z         NaN  \n",
       "1  2013-04-01T00:00:00.000000Z  2013-04-02T00:00:00.0000000Z         NaN  \n",
       "2  2013-04-02T00:00:00.000000Z  2013-04-03T00:00:00.0000000Z         NaN  \n",
       "3  2013-04-03T00:00:00.000000Z  2013-04-04T00:00:00.0000000Z         NaN  \n",
       "4  2013-04-04T00:00:00.000000Z  2013-04-05T00:00:00.0000000Z         NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bt = pd.read_csv(\"BITFINEX_SPOT_BTC_USD/1DAY_2013-03-31&2018-09-20.csv\")\n",
    "data_bt['time_close'] = pd.to_datetime(data_bt['time_close'])\n",
    "data_bt = data_bt.sort_values(by=['time_close']).reset_index(drop=True)\n",
    "data_bt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_open           False\n",
       "price_high           False\n",
       "price_low            False\n",
       "price_close          False\n",
       "volume_traded        False\n",
       "trades_count         False\n",
       "time_close           False\n",
       "time_open            False\n",
       "time_period_start    False\n",
       "time_period_end      False\n",
       "market_cap           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bt.dropna(inplace=True)\n",
    "data_bt.reset_index(drop=True, inplace=True)\n",
    "data_bt.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = pd.to_datetime(data_bt[\"time_close\"])\n",
    "data_open = data_bt[\"price_open\"]\n",
    "data_high = data_bt[\"price_high\"]\n",
    "data_low = data_bt[\"price_low\"]\n",
    "data_close = data_bt[\"price_close\"]\n",
    "data_vol = data_bt[\"volume_traded\"]\n",
    "data_mark = data_bt[\"market_cap\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_open = np.log(data_open)\n",
    "log_high = np.log(data_high)\n",
    "log_low = np.log(data_low)\n",
    "log_close = np.log(data_close)\n",
    "log_vol = np.log(data_vol)\n",
    "log_mark = np.log(data_mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STL Decompostion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_open = pd.DataFrame(log_open)\n",
    "log_open = log_open.set_index(date_col)\n",
    "\n",
    "log_high = pd.DataFrame(log_high)\n",
    "log_high = log_high.set_index(date_col)\n",
    "\n",
    "log_low = pd.DataFrame(log_low)\n",
    "log_low = log_low.set_index(date_col)\n",
    "\n",
    "log_close = pd.DataFrame(log_close)\n",
    "log_close = log_close.set_index(date_col)\n",
    "\n",
    "log_vol = pd.DataFrame(log_vol)\n",
    "log_vol = log_vol.set_index(date_col)\n",
    "\n",
    "log_mark = pd.DataFrame(log_mark)\n",
    "log_mark = log_mark.set_index(date_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stl_open = decompose(log_open)\n",
    "stl_high = decompose(log_high)\n",
    "stl_low = decompose(log_low)\n",
    "stl_close = decompose(log_close)\n",
    "stl_vol = decompose(log_vol)\n",
    "stl_mark = decompose(log_mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deasonal TS component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "deseason_open  = (stl_open.resid + stl_open.trend).iloc[:,0]\n",
    "deseason_high  = (stl_high.resid + stl_high.trend).iloc[:,0]\n",
    "deseason_low   = (stl_low.resid + stl_low.trend).iloc[:,0]\n",
    "deseason_close = (stl_close.resid + stl_close.trend).iloc[:,0]\n",
    "deseason_vol   = (stl_vol.resid + stl_vol.trend).iloc[:,0]\n",
    "deseason_mark  = (stl_mark.resid + stl_mark.trend).iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Normalized Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: Series.strides is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "date_col_win_in = rolling_window(date_col[0:(len(data_bt)-out_win)], in_win, 1)\n",
    "date_col_win_in_exp = np.expand_dims(date_col_win_in, axis=2)\n",
    "\n",
    "data_open_win_in = rolling_window(deseason_open[0:(len(deseason_open)-out_win)], in_win, 1)\n",
    "data_open_win_in = pd.DataFrame(data_open_win_in) \n",
    "norm_open_win_in = data_open_win_in.subtract(data_open_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_open_win_in_exp = np.expand_dims(norm_open_win_in.values, axis=2)\n",
    "\n",
    "data_high_win_in = rolling_window(deseason_high[0:(len(deseason_high)-out_win)], in_win, 1)\n",
    "data_high_win_in = pd.DataFrame(data_high_win_in) \n",
    "norm_high_win_in = data_high_win_in.subtract(data_high_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_high_win_in_exp = np.expand_dims(norm_high_win_in.values, axis=2)\n",
    "\n",
    "data_low_win_in = rolling_window(deseason_low[0:(len(deseason_low)-out_win)], in_win, 1)\n",
    "data_low_win_in = pd.DataFrame(data_low_win_in) \n",
    "norm_low_win_in = data_low_win_in.subtract(data_low_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_low_win_in_exp = np.expand_dims(norm_low_win_in.values, axis=2)\n",
    "\n",
    "data_close_win_in = rolling_window(deseason_close[0:(len(deseason_close)-out_win)], in_win, 1)\n",
    "data_close_win_in = pd.DataFrame(data_close_win_in) \n",
    "norm_close_win_in = data_close_win_in.subtract(data_close_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_close_win_in_exp = np.expand_dims(norm_close_win_in.values, axis=2)\n",
    "\n",
    "data_vol_win_in = rolling_window(deseason_vol[0:(len(deseason_vol)-out_win)], in_win, 1)\n",
    "data_vol_win_in = pd.DataFrame(data_vol_win_in) \n",
    "norm_vol_win_in = data_vol_win_in.subtract(data_vol_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_vol_win_in_exp = np.expand_dims(norm_vol_win_in.values, axis=2)\n",
    "\n",
    "data_mark_win_in = rolling_window(deseason_mark[0:(len(deseason_mark)-out_win)], in_win, 1)\n",
    "data_mark_win_in = pd.DataFrame(data_mark_win_in) \n",
    "norm_mark_win_in = data_mark_win_in.subtract(data_mark_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_mark_win_in_exp = np.expand_dims(norm_mark_win_in.values, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Normalized Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: Series.strides is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "date_col_win_out = rolling_window(date_col[in_win:len(data_bt)], out_win, 1)\n",
    "date_col_win_out_exp = np.expand_dims(date_col_win_out, axis=2)\n",
    "\n",
    "data_high_win_out = rolling_window(deseason_high[in_win:len(deseason_high)], out_win, 1)\n",
    "data_high_win_out = pd.DataFrame(data_high_win_out) \n",
    "norm_high_win_out = data_high_win_out.subtract(data_high_win_in.iloc[:,out_win-1], axis='index')\n",
    "norm_high_win_out_exp = np.expand_dims(norm_high_win_out.values, axis=2)\n",
    "\n",
    "data_low_win_out = rolling_window(deseason_low[in_win:len(deseason_high)], out_win, 1)\n",
    "data_low_win_out = pd.DataFrame(data_low_win_out) \n",
    "norm_low_win_out = data_low_win_out.subtract(data_low_win_in.iloc[:,out_win-1], axis='index')\n",
    "norm_low_win_out_exp = np.expand_dims(norm_low_win_out.values, axis=2)\n",
    "\n",
    "data_close_win_out = rolling_window(deseason_close[in_win:len(deseason_high)], out_win, 1)\n",
    "data_close_win_out = pd.DataFrame(data_close_win_out) \n",
    "norm_close_win_out = data_close_win_out.subtract(data_close_win_in.iloc[:,out_win-1], axis='index')\n",
    "norm_close_win_out_exp = np.expand_dims(norm_close_win_out.values, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Data for Training in High Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1934, 15, 6)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all = np.dstack((norm_open_win_in_exp, norm_high_win_in_exp, norm_low_win_in_exp\n",
    "                   ,norm_close_win_in_exp, norm_vol_win_in_exp, norm_mark_win_in_exp))\n",
    "x_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1934, 12, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all = np.dstack((norm_high_win_out_exp, norm_low_win_out_exp, norm_close_win_out_exp))\n",
    "y_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Validation Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 15, 6) (1740, 15, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.10,shuffle=False)\n",
    "\n",
    "print(X_test.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Deep Learning Architecture using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import LSTM, RepeatVector, TimeDistributed, Dense, Activation,Permute,Conv1D,GaussianNoise,Dropout,regularizers,Conv2D,Reshape\n",
    "from keras.optimizers import SGD, nadam,adam\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = 256\n",
    "nets = 512\n",
    "batch_size = 40\n",
    "model = Sequential()  \n",
    "#model.add(LSTM(batch_input_shape = (batch_size,15,6), units=hidden_neurons, stateful = False, return_sequences=False))  \n",
    "model.add(Conv1D(nets, 3, strides=32, padding='same', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Reshape((nets, -1)))\n",
    "model.add(Permute((2, 1)))\n",
    "model.add(LSTM(units=hidden_neurons, stateful = False, return_sequences=False))\n",
    "#model.add(LSTM(32)\n",
    "#model.add(LSTM(units=hidden_neurons, input_shape=(X_train.shape[1], X_train.shape[2]), stateful = False, return_sequences=False))  \n",
    "model.add(RepeatVector(out_win))\n",
    "model.add(LSTM(units=hidden_neurons,stateful = False, return_sequences=True)) \n",
    "#model.add(TimeDistributed(GaussianNoise(0.005)))\n",
    "model.add(TimeDistributed(Dense(3,\n",
    "                               #use_bias=False, bias_initializer='zeros',\n",
    "                               kernel_regularizer=regularizers.l2(0.0008),\n",
    "                               )))\n",
    "\n",
    "model.add(TimeDistributed(Activation('linear')))  \n",
    "#sgd = SGD(lr=0.01, decay=0.9, momentum=0.9, nesterov=True)\n",
    "#optm = nadam(lr=0.0001)\n",
    "model.compile(loss='mae', optimizer=\"nadam\", metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 1, 512)            9728      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "permute_2 (Permute)          (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 12, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 12, 256)           525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 12, 3)             771       \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 12, 3)             0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 3)             0         \n",
      "=================================================================\n",
      "Total params: 1,323,267\n",
      "Trainable params: 1,323,267\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1740 samples, validate on 194 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.1008 - acc: 0.3580 - val_loss: 0.0898 - val_acc: 0.3436\n",
      "Epoch 2/100\n",
      " - 9s - loss: 0.0968 - acc: 0.3383 - val_loss: 0.0860 - val_acc: 0.3466\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.0941 - acc: 0.3509 - val_loss: 0.0836 - val_acc: 0.3342\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0931 - acc: 0.3427 - val_loss: 0.0837 - val_acc: 0.3565\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0929 - acc: 0.3453 - val_loss: 0.0836 - val_acc: 0.3376\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0925 - acc: 0.3683 - val_loss: 0.0840 - val_acc: 0.3389\n",
      "Epoch 7/100\n",
      " - 7s - loss: 0.0911 - acc: 0.3672 - val_loss: 0.0832 - val_acc: 0.3329\n",
      "Epoch 8/100\n",
      " - 7s - loss: 0.0908 - acc: 0.3672 - val_loss: 0.0823 - val_acc: 0.3398\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.0906 - acc: 0.3695 - val_loss: 0.0827 - val_acc: 0.3368\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.0907 - acc: 0.3672 - val_loss: 0.0824 - val_acc: 0.3299\n",
      "Epoch 11/100\n",
      " - 7s - loss: 0.0905 - acc: 0.3636 - val_loss: 0.0827 - val_acc: 0.3312\n",
      "Epoch 12/100\n",
      " - 7s - loss: 0.0903 - acc: 0.3633 - val_loss: 0.0826 - val_acc: 0.3299\n",
      "Epoch 13/100\n",
      " - 7s - loss: 0.0903 - acc: 0.3644 - val_loss: 0.0825 - val_acc: 0.3329\n",
      "Epoch 14/100\n",
      " - 7s - loss: 0.0903 - acc: 0.3648 - val_loss: 0.0825 - val_acc: 0.3363\n",
      "Epoch 15/100\n",
      " - 7s - loss: 0.0903 - acc: 0.3648 - val_loss: 0.0824 - val_acc: 0.3355\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.0903 - acc: 0.3640 - val_loss: 0.0824 - val_acc: 0.3351\n",
      "Epoch 17/100\n",
      " - 7s - loss: 0.0903 - acc: 0.3644 - val_loss: 0.0824 - val_acc: 0.3376\n",
      "Epoch 18/100\n",
      " - 7s - loss: 0.0903 - acc: 0.3645 - val_loss: 0.0824 - val_acc: 0.3385\n",
      "Epoch 19/100\n",
      " - 7s - loss: 0.0902 - acc: 0.3650 - val_loss: 0.0824 - val_acc: 0.3406\n",
      "Epoch 20/100\n",
      " - 7s - loss: 0.0902 - acc: 0.3643 - val_loss: 0.0824 - val_acc: 0.3398\n",
      "Epoch 21/100\n",
      " - 7s - loss: 0.0902 - acc: 0.3638 - val_loss: 0.0824 - val_acc: 0.3389\n",
      "Epoch 22/100\n",
      " - 7s - loss: 0.0902 - acc: 0.3654 - val_loss: 0.0823 - val_acc: 0.3398\n",
      "Epoch 23/100\n",
      " - 7s - loss: 0.0902 - acc: 0.3651 - val_loss: 0.0823 - val_acc: 0.3393\n",
      "Epoch 24/100\n",
      " - 7s - loss: 0.0902 - acc: 0.3651 - val_loss: 0.0824 - val_acc: 0.3406\n",
      "Epoch 25/100\n",
      " - 7s - loss: 0.0902 - acc: 0.3645 - val_loss: 0.0824 - val_acc: 0.3411\n",
      "Epoch 26/100\n",
      " - 7s - loss: 0.0902 - acc: 0.3648 - val_loss: 0.0823 - val_acc: 0.3419\n",
      "Epoch 27/100\n",
      " - 7s - loss: 0.0902 - acc: 0.3651 - val_loss: 0.0823 - val_acc: 0.3411\n",
      "Epoch 28/100\n",
      " - 7s - loss: 0.0902 - acc: 0.3653 - val_loss: 0.0823 - val_acc: 0.3411\n",
      "Epoch 29/100\n",
      " - 7s - loss: 0.0902 - acc: 0.3651 - val_loss: 0.0823 - val_acc: 0.3419\n",
      "Epoch 30/100\n",
      " - 9s - loss: 0.0902 - acc: 0.3651 - val_loss: 0.0823 - val_acc: 0.3419\n",
      "Epoch 31/100\n",
      " - 9s - loss: 0.0902 - acc: 0.3641 - val_loss: 0.0823 - val_acc: 0.3415\n",
      "Epoch 32/100\n",
      " - 8s - loss: 0.0902 - acc: 0.3655 - val_loss: 0.0823 - val_acc: 0.3424\n",
      "Epoch 33/100\n"
     ]
    }
   ],
   "source": [
    "# for i in range(200):\n",
    "#     model.fit(X_train, y_train,\n",
    "#               epochs=1,\n",
    "#               batch_size=batch_size,\n",
    "#               verbose=2,\n",
    "#               validation_data = (X_test, y_test))\n",
    "#     model.reset_states()\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',patience=3, min_lr=0.00001,factor=0.1)\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          verbose=2,\n",
    "          callbacks=[reduce_lr],\n",
    "          validation_data = (X_test, y_test))\n",
    "\n",
    "# Save the weights\n",
    "model.save_weights('model_weights.h5')\n",
    "\n",
    "# Save the model architecture\n",
    "with open('model_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model reconstruction from JSON file\n",
    "with open('model_architecture.json', 'r') as f:\n",
    "    model = model_from_json(f.read())\n",
    "\n",
    "# Load weights into the new model\n",
    "model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrying out Prediction on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renormalizing and seasonalizing the predictions and true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_high  = pd.DataFrame(rolling_window(stl_high.seasonal.iloc[:,0][in_win:len(stl_high.seasonal)], out_win, 1))\n",
    "season_low   = pd.DataFrame(rolling_window(stl_low.seasonal.iloc[:,0][in_win:len(stl_low.seasonal)], out_win, 1))\n",
    "season_close = pd.DataFrame(rolling_window(stl_close.seasonal.iloc[:,0][in_win:len(stl_close.seasonal)], out_win, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_high_pr  = pd.DataFrame(rolling_window(stl_high.seasonal.iloc[:,0][0:(len(stl_high.seasonal)-out_win)], in_win, 1))\n",
    "season_high_pr.drop(season_high_pr.columns[0:(in_win-out_win)], axis=1, inplace=True)\n",
    "season_high_pr.columns = np.arange(len(season_high_pr.columns))\n",
    "season_low_pr   = pd.DataFrame(rolling_window(stl_low.seasonal.iloc[:,0][0:(len(stl_low.seasonal)-out_win)], in_win, 1))\n",
    "season_low_pr.drop(season_low_pr.columns[0:(in_win-out_win)], axis=1, inplace=True)\n",
    "season_low_pr.columns = np.arange(len(season_low_pr.columns))\n",
    "season_close_pr = pd.DataFrame(rolling_window(stl_close.seasonal.iloc[:,0][0:(len(stl_close.seasonal)-out_win)], in_win, 1))\n",
    "season_close_pr.drop(season_close_pr.columns[0:(in_win-out_win)], axis=1, inplace=True)\n",
    "season_close_pr.columns = np.arange(len(season_close_pr.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_pred  = pd.DataFrame(y_pred[:,:,0])\n",
    "low_pred   = pd.DataFrame(y_pred[:,:,1])\n",
    "close_pred = pd.DataFrame(y_pred[:,:,2])\n",
    "\n",
    "high_denorm_pred  = high_pred.add(data_high_win_in.iloc[X_train.shape[0]:,out_win-1].reset_index(drop=True), axis='index')\n",
    "low_denorm_pred   = low_pred.add(data_low_win_in.iloc[X_train.shape[0]:,out_win-1].reset_index(drop=True), axis='index')\n",
    "close_denorm_pred = close_pred.add(data_close_win_in.iloc[X_train.shape[0]:,out_win-1].reset_index(drop=True), axis='index')\n",
    "\n",
    "deseason_high_pred  = high_denorm_pred.add(season_high_pr.iloc[X_train.shape[0]:,].reset_index(drop=True), axis='index')\n",
    "deseason_low_pred   = low_denorm_pred.add(season_low_pr.iloc[X_train.shape[0]:,].reset_index(drop=True), axis='index')\n",
    "deseason_close_pred = close_denorm_pred.add(season_close_pr.iloc[X_train.shape[0]:,].reset_index(drop=True), axis='index')\n",
    "\n",
    "pred_high  = np.exp(deseason_high_pred)\n",
    "pred_low   = np.exp(deseason_low_pred)\n",
    "pred_close = np.exp(deseason_close_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_test  = pd.DataFrame(y_test[:,:,0])\n",
    "low_test   = pd.DataFrame(y_test[:,:,1])\n",
    "close_test = pd.DataFrame(y_test[:,:,2])\n",
    "\n",
    "high_denorm_test  = high_test.add(data_high_win_in.iloc[X_train.shape[0]:,out_win-1].reset_index(drop=True), axis='index')\n",
    "low_denorm_test   = low_test.add(data_low_win_in.iloc[X_train.shape[0]:,out_win-1].reset_index(drop=True), axis='index')\n",
    "close_denorm_test = close_test.add(data_close_win_in.iloc[X_train.shape[0]:,out_win-1].reset_index(drop=True), axis='index')\n",
    "\n",
    "deseason_high_test  = high_denorm_test.add(season_high.iloc[X_train.shape[0]:,].reset_index(drop=True))\n",
    "deseason_low_test   = low_denorm_test.add(season_low.iloc[X_train.shape[0]:,].reset_index(drop=True))\n",
    "deseason_close_test = close_denorm_test.add(season_close.iloc[X_train.shape[0]:,].reset_index(drop=True))\n",
    "\n",
    "test_high  = np.exp(deseason_high_test)\n",
    "test_low   = np.exp(deseason_low_test)\n",
    "test_close = np.exp(deseason_close_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test[1,:,1]\n",
    "date_col_win_test = rolling_window(date_col[0:(len(data_bt)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "date_col_win_test = pd.DataFrame(date_col_win_test)\n",
    "\n",
    "data_open_win_test = rolling_window(data_open[0:(len(data_open)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "data_open_win_test = pd.DataFrame(data_open_win_test) \n",
    "\n",
    "data_high_win_test = rolling_window(data_high[0:(len(data_high)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "data_high_win_test = pd.DataFrame(data_high_win_test) \n",
    "\n",
    "\n",
    "data_low_win_test = rolling_window(data_low[0:(len(data_low)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "data_low_win_test = pd.DataFrame(data_low_win_test) \n",
    "\n",
    "\n",
    "data_close_win_test = rolling_window(data_close[0:(len(data_close)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "data_close_win_test = pd.DataFrame(data_close_win_test) \n",
    "\n",
    "\n",
    "data_vol_win_test = rolling_window(data_vol[0:(len(data_vol)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "data_vol_win_test = pd.DataFrame(data_vol_win_test) \n",
    "\n",
    "\n",
    "data_mark_win_test = rolling_window(data_mark[0:(len(data_mark)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "data_mark_win_test = pd.DataFrame(data_mark_win_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col_win_pred = pd.DataFrame(date_col_win_out[X_train.shape[0]:])\n",
    "date_col_win_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data_high_win_test))\n",
    "data_high_win_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "for index,row in pred_close.iterrows():\n",
    "    plt.figure()\n",
    "    plt.plot(date_col_win_pred.iloc[index,:],pred_close.iloc[index,:],color='r',marker = '.')\n",
    "    plt.plot(date_col_win_test.iloc[index,:],data_close_win_test.iloc[index,:],color='g',marker = '.')\n",
    "    plt.plot(date_col_win_pred.iloc[index,:],test_close.iloc[index,:],color='b',marker = '.')\n",
    "    if index == 5:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "error_high = []\n",
    "error_low = []\n",
    "error_close = []\n",
    "\n",
    "for index,row in pred_high.iterrows():\n",
    "    error_high.append(smape(test_high.iloc[index,:], pred_high.iloc[index,:]))\n",
    "\n",
    "for index,row in pred_low.iterrows():\n",
    "    error_low.append(smape(test_low.iloc[index,:], pred_low.iloc[index,:]))\n",
    "    \n",
    "for index,row in pred_close.iterrows():\n",
    "    error_close.append(smape(test_close.iloc[index,:], pred_close.iloc[index,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMAPE ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"High prediciton SMAPE score : \",sum(error_high)/len(error_high))\n",
    "print(\"Low prediciton SMAPE score : \",sum(error_low)/len(error_low))\n",
    "print(\"Close prediciton SMAPE score : \",sum(error_close)/len(error_close))\n",
    "print(\"Overall SMAPE score : \",((sum(error_high)/len(error_high)) + (sum(error_low)/len(error_low)) + (sum(error_close)/len(error_close)))/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_pred_check = data_close_win_test.iloc[:,in_win-1]-pred_close.iloc[:,0]\n",
    "close_true_check = data_close_win_test.iloc[:,in_win-1]-test_close.iloc[:,0]\n",
    "\n",
    "high_pred_check = data_high_win_test.iloc[:,in_win-1]-pred_high.iloc[:,0]\n",
    "high_true_check = data_high_win_test.iloc[:,in_win-1]-test_high.iloc[:,0]\n",
    "\n",
    "low_pred_check = data_low_win_test.iloc[:,in_win-1]-pred_low.iloc[:,0]\n",
    "low_true_check = data_low_win_test.iloc[:,in_win-1]-test_low.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-Score , Precision Recall, True Positive Rate & True Negative Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_tp = 0\n",
    "close_tn = 0\n",
    "close_fp = 0\n",
    "close_fn = 0\n",
    "\n",
    "high_tp = 0\n",
    "high_tn = 0\n",
    "high_fp = 0\n",
    "high_fn = 0\n",
    "\n",
    "low_tp = 0\n",
    "low_tn = 0\n",
    "low_fp = 0\n",
    "low_fn = 0\n",
    "for i in range(0,len(close_pred_check)):\n",
    "    if(close_true_check[i] >= 0  and close_pred_check[i] >= 0):\n",
    "        close_tp += 1\n",
    "    if(close_true_check[i] >= 0  and close_pred_check[i] < 0):\n",
    "        close_tn += 1 \n",
    "    if(close_true_check[i] < 0  and close_pred_check[i] < 0):\n",
    "        close_fp += 1\n",
    "    if(close_true_check[i] < 0  and close_pred_check[i] >= 0):\n",
    "        close_fn += 1\n",
    "\n",
    "    if(high_true_check[i] >= 0  and high_pred_check[i] >= 0):\n",
    "        high_tp += 1\n",
    "    if(high_true_check[i] >= 0  and high_pred_check[i] < 0):\n",
    "        high_tn += 1 \n",
    "    if(high_true_check[i] < 0  and high_pred_check[i] < 0):\n",
    "        high_fp += 1\n",
    "    if(high_true_check[i] < 0  and high_pred_check[i] >= 0):\n",
    "        high_fn += 1\n",
    "    \n",
    "    if(low_true_check[i] >= 0  and low_pred_check[i] >= 0):\n",
    "        low_tp += 1\n",
    "    if(low_true_check[i] >= 0  and low_pred_check[i] < 0):\n",
    "        low_tn += 1 \n",
    "    if(low_true_check[i] < 0  and low_pred_check[i] < 0):\n",
    "        low_fp += 1\n",
    "    if(low_true_check[i] < 0  and low_pred_check[i] >= 0):\n",
    "        low_fn += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(tp,fp):\n",
    "    return(tp/(tp + fp))\n",
    "\n",
    "def recall(tp,fn):\n",
    "    return(tp/(tp + fn))\n",
    "\n",
    "def f_score(precision,recall):\n",
    "    return(2*((precision * recall)/(precision + recall)))\n",
    "\n",
    "def tp_rate(tp,fn):\n",
    "    return(tp/(tp+fn))\n",
    "\n",
    "def fp_rate(fp,tn):\n",
    "    return(fp/(fp+tn))\n",
    "\n",
    "def Accuracy(TP,TN,FP,FN):\n",
    "    return (TP + TN) / (TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_precision  = [precision(close_tp,close_fp) , precision(close_tn,close_fn)]\n",
    "close_recall     = [recall(close_tp,close_fn) , recall(close_tn,close_fp)]\n",
    "close_f_score    = [f_score(close_precision[0],close_recall[0]) , f_score(close_precision[1],close_recall[1])]\n",
    "close_tp_rate    = [tp_rate(close_tp,close_fn), tp_rate(close_tn,close_fp)]\n",
    "close_fp_rate    = [fp_rate(close_fp,close_tn) , fp_rate(close_fn,close_tp)]\n",
    "close_Accuracy   = [Accuracy(close_tp,close_tn,close_fp,close_fn), Accuracy(close_tn,close_tp,close_fn,close_fp)]\n",
    "\n",
    "print(\"close precision : \",close_precision)\n",
    "print(\"close recall    : \",close_recall)\n",
    "print(\"close f_score   : \",close_f_score)\n",
    "print(\"close tp_rate   : \",close_tp_rate)\n",
    "print(\"close fp_rate   : \",close_fp_rate)\n",
    "print(\"close Accuracy  : \",close_Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_precision  = [precision(high_tp,high_fp) , precision(high_tn,high_fn)]\n",
    "high_recall     = [recall(high_tp,high_fn) , recall(high_tn,high_fp)]\n",
    "high_f_score    = [f_score(high_precision[0],high_recall[0]) , f_score(high_precision[1],high_recall[1])]\n",
    "high_tp_rate    = [tp_rate(high_tp,high_fn), tp_rate(high_tn,high_fp)]\n",
    "high_fp_rate    = [fp_rate(high_fp,high_tn) , fp_rate(high_fn,high_tp)]\n",
    "high_Accuracy   = [Accuracy(high_tp,high_tn,high_fp,high_fn), Accuracy(high_tn,high_tp,high_fn,high_fp)]\n",
    "\n",
    "print(\"high precision : \",high_precision)\n",
    "print(\"high recall    : \",high_recall)\n",
    "print(\"high f_score   : \",high_f_score)\n",
    "print(\"high tp_rate   : \",high_tp_rate)\n",
    "print(\"high fp_rate   : \",high_fp_rate)\n",
    "print(\"high Accuracy  : \",high_Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_precision  = [precision(low_tp,low_fp) , precision(low_tn,low_fn)]\n",
    "low_recall     = [recall(low_tp,low_fn) , recall(low_tn,low_fp)]\n",
    "low_f_score    = [f_score(low_precision[0],low_recall[0]) , f_score(low_precision[1],low_recall[1])]\n",
    "low_tp_rate    = [tp_rate(low_tp,low_fn), tp_rate(low_tn,low_fp)]\n",
    "low_fp_rate    = [fp_rate(low_fp,low_tn) , fp_rate(low_fn,low_tp)]\n",
    "low_Accuracy   = [Accuracy(low_tp,low_tn,low_fp,low_fn), Accuracy(low_tn,low_tp,low_fn,low_fp)]\n",
    "\n",
    "print(\"low precision : \",low_precision)\n",
    "print(\"low recall    : \",low_recall)\n",
    "print(\"low f_score   : \",low_f_score)\n",
    "print(\"low tp_rate   : \",low_tp_rate)\n",
    "print(\"low fp_rate   : \",low_fp_rate)\n",
    "print(\"low Accuracy ,: \",low_Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
