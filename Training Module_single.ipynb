{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stldecompose import decompose\n",
    "from matplotlib import pyplot\n",
    "from keras.models import model_from_json\n",
    "#https://stackoverflow.com/questions/48356464/how-to-model-convolutional-recurrent-network-crnn-in-keras\n",
    "#https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/\n",
    "#https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras\n",
    "#https://github.com/keras-team/keras/issues/6063\n",
    "#https://stackoverflow.com/questions/34357617/append-2d-array-to-3d-array-extending-third-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(a, window, step_size):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window +2  - step_size, window)\n",
    "    strides = a.strides + (a.strides[-1] * step_size,)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_win = 15\n",
    "out_win = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMC Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_bt = pd.read_csv(\"cmc_btc.csv\")\n",
    "# data_bt['Date'] = pd.to_datetime(data_bt['Date'])\n",
    "# data_bt = data_bt.sort_values(by=['Date']).reset_index(drop=True)\n",
    "# data_bt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_col = pd.to_datetime(data_bt[\"Date\"])\n",
    "# data_open = data_bt[\"Open*\"]\n",
    "# data_high = data_bt[\"High\"]\n",
    "# data_low = data_bt[\"Low\"]\n",
    "# data_close = data_bt[\"Close**\"]\n",
    "# data_vol = data_bt[\"Volume\"]\n",
    "# data_mark = data_bt[\"Market Cap\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BITFINEX DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_open</th>\n",
       "      <th>price_high</th>\n",
       "      <th>price_low</th>\n",
       "      <th>price_close</th>\n",
       "      <th>volume_traded</th>\n",
       "      <th>trades_count</th>\n",
       "      <th>time_close</th>\n",
       "      <th>time_open</th>\n",
       "      <th>time_period_start</th>\n",
       "      <th>time_period_end</th>\n",
       "      <th>market_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.250000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>93.03000</td>\n",
       "      <td>93.100010</td>\n",
       "      <td>390.827224</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-03-31 23:36:44</td>\n",
       "      <td>2013-03-31T22:07:48.0000000Z</td>\n",
       "      <td>2013-03-31T22:00:00.000000Z</td>\n",
       "      <td>2013-04-01T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.170000</td>\n",
       "      <td>105.900000</td>\n",
       "      <td>92.49999</td>\n",
       "      <td>102.370000</td>\n",
       "      <td>4919.654127</td>\n",
       "      <td>627</td>\n",
       "      <td>2013-04-01 23:41:42</td>\n",
       "      <td>2013-04-01T00:05:39.0000000Z</td>\n",
       "      <td>2013-04-01T00:00:00.000000Z</td>\n",
       "      <td>2013-04-02T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.800000</td>\n",
       "      <td>118.388067</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>117.989990</td>\n",
       "      <td>9084.832816</td>\n",
       "      <td>1205</td>\n",
       "      <td>2013-04-02 23:54:35</td>\n",
       "      <td>2013-04-02T00:00:11.0000000Z</td>\n",
       "      <td>2013-04-02T00:00:00.000000Z</td>\n",
       "      <td>2013-04-03T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.579097</td>\n",
       "      <td>146.880000</td>\n",
       "      <td>101.51088</td>\n",
       "      <td>134.952969</td>\n",
       "      <td>12909.402178</td>\n",
       "      <td>2502</td>\n",
       "      <td>2013-04-03 23:59:37</td>\n",
       "      <td>2013-04-03T00:07:29.0000000Z</td>\n",
       "      <td>2013-04-03T00:00:00.000000Z</td>\n",
       "      <td>2013-04-04T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131.779686</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>119.00000</td>\n",
       "      <td>132.681000</td>\n",
       "      <td>6910.100414</td>\n",
       "      <td>1456</td>\n",
       "      <td>2013-04-04 23:50:09</td>\n",
       "      <td>2013-04-04T00:02:15.0000000Z</td>\n",
       "      <td>2013-04-04T00:00:00.000000Z</td>\n",
       "      <td>2013-04-05T00:00:00.0000000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price_open  price_high  price_low  price_close  volume_traded  \\\n",
       "0   93.250000  100.000000   93.03000    93.100010     390.827224   \n",
       "1   93.170000  105.900000   92.49999   102.370000    4919.654127   \n",
       "2  102.800000  118.388067   99.00000   117.989990    9084.832816   \n",
       "3  116.579097  146.880000  101.51088   134.952969   12909.402178   \n",
       "4  131.779686  143.000000  119.00000   132.681000    6910.100414   \n",
       "\n",
       "   trades_count          time_close                     time_open  \\\n",
       "0            55 2013-03-31 23:36:44  2013-03-31T22:07:48.0000000Z   \n",
       "1           627 2013-04-01 23:41:42  2013-04-01T00:05:39.0000000Z   \n",
       "2          1205 2013-04-02 23:54:35  2013-04-02T00:00:11.0000000Z   \n",
       "3          2502 2013-04-03 23:59:37  2013-04-03T00:07:29.0000000Z   \n",
       "4          1456 2013-04-04 23:50:09  2013-04-04T00:02:15.0000000Z   \n",
       "\n",
       "             time_period_start               time_period_end  market_cap  \n",
       "0  2013-03-31T22:00:00.000000Z  2013-04-01T00:00:00.0000000Z         NaN  \n",
       "1  2013-04-01T00:00:00.000000Z  2013-04-02T00:00:00.0000000Z         NaN  \n",
       "2  2013-04-02T00:00:00.000000Z  2013-04-03T00:00:00.0000000Z         NaN  \n",
       "3  2013-04-03T00:00:00.000000Z  2013-04-04T00:00:00.0000000Z         NaN  \n",
       "4  2013-04-04T00:00:00.000000Z  2013-04-05T00:00:00.0000000Z         NaN  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bt = pd.read_csv(\"BITFINEX_SPOT_BTC_USD/1DAY_2013-03-31&2018-09-20.csv\")\n",
    "data_bt['time_close'] = pd.to_datetime(data_bt['time_close'])\n",
    "data_bt = data_bt.sort_values(by=['time_close']).reset_index(drop=True)\n",
    "data_bt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_open           False\n",
       "price_high           False\n",
       "price_low            False\n",
       "price_close          False\n",
       "volume_traded        False\n",
       "trades_count         False\n",
       "time_close           False\n",
       "time_open            False\n",
       "time_period_start    False\n",
       "time_period_end      False\n",
       "market_cap           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bt.dropna(inplace=True)\n",
    "data_bt.reset_index(drop=True, inplace=True)\n",
    "data_bt.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = pd.to_datetime(data_bt[\"time_close\"])\n",
    "data_open = data_bt[\"price_open\"]\n",
    "data_high = data_bt[\"price_high\"]\n",
    "data_low = data_bt[\"price_low\"]\n",
    "data_close = data_bt[\"price_close\"]\n",
    "data_vol = data_bt[\"volume_traded\"]\n",
    "data_mark = data_bt[\"market_cap\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_open = np.log(data_open)\n",
    "log_high = np.log(data_high)\n",
    "log_low = np.log(data_low)\n",
    "log_close = np.log(data_close)\n",
    "log_vol = np.log(data_vol)\n",
    "log_mark = np.log(data_mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STL Decompostion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_open = pd.DataFrame(log_open)\n",
    "log_open = log_open.set_index(date_col)\n",
    "\n",
    "log_high = pd.DataFrame(log_high)\n",
    "log_high = log_high.set_index(date_col)\n",
    "\n",
    "log_low = pd.DataFrame(log_low)\n",
    "log_low = log_low.set_index(date_col)\n",
    "\n",
    "log_close = pd.DataFrame(log_close)\n",
    "log_close = log_close.set_index(date_col)\n",
    "\n",
    "log_vol = pd.DataFrame(log_vol)\n",
    "log_vol = log_vol.set_index(date_col)\n",
    "\n",
    "log_mark = pd.DataFrame(log_mark)\n",
    "log_mark = log_mark.set_index(date_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "stl_open = decompose(log_open)\n",
    "stl_high = decompose(log_high)\n",
    "stl_low = decompose(log_low)\n",
    "stl_close = decompose(log_close)\n",
    "stl_vol = decompose(log_vol)\n",
    "stl_mark = decompose(log_mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deasonal TS component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "deseason_open  = (stl_open.resid + stl_open.trend).iloc[:,0]\n",
    "deseason_high  = (stl_high.resid + stl_high.trend).iloc[:,0]\n",
    "deseason_low   = (stl_low.resid + stl_low.trend).iloc[:,0]\n",
    "deseason_close = (stl_close.resid + stl_close.trend).iloc[:,0]\n",
    "deseason_vol   = (stl_vol.resid + stl_vol.trend).iloc[:,0]\n",
    "deseason_mark  = (stl_mark.resid + stl_mark.trend).iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Normalized Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: Series.strides is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "date_col_win_in = rolling_window(date_col[0:(len(data_bt)-out_win)], in_win, 1)\n",
    "date_col_win_in_exp = np.expand_dims(date_col_win_in, axis=2)\n",
    "\n",
    "data_open_win_in = rolling_window(deseason_open[0:(len(deseason_open)-out_win)], in_win, 1)\n",
    "data_open_win_in = pd.DataFrame(data_open_win_in) \n",
    "norm_open_win_in = data_open_win_in.subtract(data_open_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_open_win_in_exp = np.expand_dims(norm_open_win_in.values, axis=2)\n",
    "\n",
    "data_high_win_in = rolling_window(deseason_high[0:(len(deseason_high)-out_win)], in_win, 1)\n",
    "data_high_win_in = pd.DataFrame(data_high_win_in) \n",
    "norm_high_win_in = data_high_win_in.subtract(data_high_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_high_win_in_exp = np.expand_dims(norm_high_win_in.values, axis=2)\n",
    "\n",
    "data_low_win_in = rolling_window(deseason_low[0:(len(deseason_low)-out_win)], in_win, 1)\n",
    "data_low_win_in = pd.DataFrame(data_low_win_in) \n",
    "norm_low_win_in = data_low_win_in.subtract(data_low_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_low_win_in_exp = np.expand_dims(norm_low_win_in.values, axis=2)\n",
    "\n",
    "data_close_win_in = rolling_window(deseason_close[0:(len(deseason_close)-out_win)], in_win, 1)\n",
    "data_close_win_in = pd.DataFrame(data_close_win_in) \n",
    "norm_close_win_in = data_close_win_in.subtract(data_close_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_close_win_in_exp = np.expand_dims(norm_close_win_in.values, axis=2)\n",
    "\n",
    "data_vol_win_in = rolling_window(deseason_vol[0:(len(deseason_vol)-out_win)], in_win, 1)\n",
    "data_vol_win_in = pd.DataFrame(data_vol_win_in) \n",
    "norm_vol_win_in = data_vol_win_in.subtract(data_vol_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_vol_win_in_exp = np.expand_dims(norm_vol_win_in.values, axis=2)\n",
    "\n",
    "data_mark_win_in = rolling_window(deseason_mark[0:(len(deseason_mark)-out_win)], in_win, 1)\n",
    "data_mark_win_in = pd.DataFrame(data_mark_win_in) \n",
    "norm_mark_win_in = data_mark_win_in.subtract(data_mark_win_in.iloc[:,in_win-1], axis='index')\n",
    "norm_mark_win_in_exp = np.expand_dims(norm_mark_win_in.values, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Normalized Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: Series.strides is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "date_col_win_out = rolling_window(date_col[in_win:len(data_bt)], out_win, 1)\n",
    "date_col_win_out_exp = np.expand_dims(date_col_win_out, axis=2)\n",
    "\n",
    "data_high_win_out = rolling_window(deseason_high[in_win:len(deseason_high)], out_win, 1)\n",
    "data_high_win_out = pd.DataFrame(data_high_win_out) \n",
    "norm_high_win_out = data_high_win_out.subtract(data_high_win_in.iloc[:,out_win-1], axis='index').values\n",
    "#norm_high_win_out_exp = np.expand_dims(norm_high_win_out.values, axis=2)\n",
    "\n",
    "data_low_win_out = rolling_window(deseason_low[in_win:len(deseason_high)], out_win, 1)\n",
    "data_low_win_out = pd.DataFrame(data_low_win_out) \n",
    "norm_low_win_out = data_low_win_out.subtract(data_low_win_in.iloc[:,out_win-1], axis='index').values\n",
    "#norm_low_win_out_exp = np.expand_dims(norm_low_win_out.values, axis=2)\n",
    "\n",
    "data_close_win_out = rolling_window(deseason_close[in_win:len(deseason_high)], out_win, 1)\n",
    "data_close_win_out = pd.DataFrame(data_close_win_out) \n",
    "norm_close_win_out = data_close_win_out.subtract(data_close_win_in.iloc[:,out_win-1], axis='index').values\n",
    "#norm_close_win_out_exp = np.expand_dims(norm_close_win_out.values, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Data for Training in High Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1934, 15, 6)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all = np.dstack((norm_open_win_in_exp, norm_high_win_in_exp, norm_low_win_in_exp\n",
    "                   ,norm_close_win_in_exp, norm_vol_win_in_exp, norm_mark_win_in_exp))\n",
    "x_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1934, 12)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_all = np.dstack((norm_high_win_out_exp, norm_low_win_out_exp, norm_close_win_out_exp))\n",
    "y_all = norm_close_win_out\n",
    "y_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Validation Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383, 15, 6) (1551, 15, 6) (1551, 12) (383, 12)\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train,  = train_test_split(x_all, y_all, test_size=0.10,shuffle=False)\n",
    "\n",
    "msk = np.random.rand(len(x_all)) < 0.81\n",
    "\n",
    "X_train = x_all[msk]\n",
    "X_test = x_all[~msk]\n",
    "\n",
    "Y_train = y_all[msk]\n",
    "Y_test = y_all[~msk]\n",
    "\n",
    "print(X_test.shape, X_train.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Deep Learning Architecture using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import LSTM, RepeatVector, TimeDistributed, Dense, Activation,Permute,Conv1D,GaussianNoise,Dropout,regularizers,Conv2D,Reshape\n",
    "from keras.optimizers import SGD, nadam,adam\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = 180\n",
    "batch_size = 1\n",
    "model = Sequential()  \n",
    "#model.add(LSTM(batch_input_shape = (batch_size,15,6), units=hidden_neurons, stateful = False, return_sequences=False))  \n",
    "model.add(LSTM(units=hidden_neurons, batch_input_shape=(batch_size,X_train.shape[1], X_train.shape[2]),stateful = True, return_sequences=False))\n",
    "model.add(GaussianNoise(0.005))\n",
    "model.add(Dense(out_win,use_bias=False, bias_initializer='zeros',kernel_regularizer=regularizers.l2(0.0008)))\n",
    "optm = nadam(lr=0.01)\n",
    "model.compile(loss='mean_squared_error', optimizer=\"nadam\", metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (1, 180)                  134640    \n",
      "_________________________________________________________________\n",
      "gaussian_noise_3 (GaussianNo (1, 180)                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, 12)                   2160      \n",
      "=================================================================\n",
      "Total params: 136,800\n",
      "Trainable params: 136,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 23s - loss: 0.0147 - acc: 0.1135 - val_loss: 0.0135 - val_acc: 0.1854\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 23s - loss: 0.0124 - acc: 0.1225 - val_loss: 0.0133 - val_acc: 0.1514\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0122 - acc: 0.1328 - val_loss: 0.0129 - val_acc: 0.1540\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 25s - loss: 0.0119 - acc: 0.1438 - val_loss: 0.0133 - val_acc: 0.1749\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0119 - acc: 0.1483 - val_loss: 0.0127 - val_acc: 0.1775\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0119 - acc: 0.1502 - val_loss: 0.0130 - val_acc: 0.1462\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 27s - loss: 0.0120 - acc: 0.1573 - val_loss: 0.0130 - val_acc: 0.1044\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0117 - acc: 0.1573 - val_loss: 0.0134 - val_acc: 0.1332\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 28s - loss: 0.0116 - acc: 0.1670 - val_loss: 0.0140 - val_acc: 0.1123\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0115 - acc: 0.1502 - val_loss: 0.0127 - val_acc: 0.1358\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0114 - acc: 0.1818 - val_loss: 0.0130 - val_acc: 0.1123\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0113 - acc: 0.1605 - val_loss: 0.0128 - val_acc: 0.1567\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0112 - acc: 0.1567 - val_loss: 0.0127 - val_acc: 0.1384\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0110 - acc: 0.1534 - val_loss: 0.0141 - val_acc: 0.1358\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 28s - loss: 0.0111 - acc: 0.1554 - val_loss: 0.0130 - val_acc: 0.1384\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 28s - loss: 0.0109 - acc: 0.1522 - val_loss: 0.0133 - val_acc: 0.1436\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 27s - loss: 0.0109 - acc: 0.1767 - val_loss: 0.0126 - val_acc: 0.1332\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 26s - loss: 0.0106 - acc: 0.1593 - val_loss: 0.0123 - val_acc: 0.1358\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 26s - loss: 0.0105 - acc: 0.1586 - val_loss: 0.0127 - val_acc: 0.1854\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 28s - loss: 0.0103 - acc: 0.1676 - val_loss: 0.0126 - val_acc: 0.1384\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 24s - loss: 0.0103 - acc: 0.1747 - val_loss: 0.0127 - val_acc: 0.1253\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 24s - loss: 0.0100 - acc: 0.1580 - val_loss: 0.0122 - val_acc: 0.1410\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 23s - loss: 0.0097 - acc: 0.1689 - val_loss: 0.0135 - val_acc: 0.1253\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 24s - loss: 0.0095 - acc: 0.1638 - val_loss: 0.0123 - val_acc: 0.1123\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 26s - loss: 0.0095 - acc: 0.1773 - val_loss: 0.0112 - val_acc: 0.1749\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 25s - loss: 0.0091 - acc: 0.1999 - val_loss: 0.0116 - val_acc: 0.1645\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 25s - loss: 0.0088 - acc: 0.1702 - val_loss: 0.0116 - val_acc: 0.1410\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 23s - loss: 0.0085 - acc: 0.1786 - val_loss: 0.0116 - val_acc: 0.1749\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 25s - loss: 0.0081 - acc: 0.1876 - val_loss: 0.0115 - val_acc: 0.1645\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 24s - loss: 0.0079 - acc: 0.2089 - val_loss: 0.0141 - val_acc: 0.1645\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 25s - loss: 0.0080 - acc: 0.1966 - val_loss: 0.0109 - val_acc: 0.1645\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 24s - loss: 0.0076 - acc: 0.2063 - val_loss: 0.0109 - val_acc: 0.1227\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 23s - loss: 0.0075 - acc: 0.2018 - val_loss: 0.0115 - val_acc: 0.1462\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 23s - loss: 0.0071 - acc: 0.2121 - val_loss: 0.0120 - val_acc: 0.1645\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 22s - loss: 0.0071 - acc: 0.2244 - val_loss: 0.0107 - val_acc: 0.1305\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 25s - loss: 0.0066 - acc: 0.2347 - val_loss: 0.0096 - val_acc: 0.2010\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 23s - loss: 0.0064 - acc: 0.2315 - val_loss: 0.0105 - val_acc: 0.2037\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 24s - loss: 0.0064 - acc: 0.2186 - val_loss: 0.0102 - val_acc: 0.1775\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 23s - loss: 0.0059 - acc: 0.2173 - val_loss: 0.0098 - val_acc: 0.2219\n",
      "Train on 1551 samples, validate on 383 samples\n",
      "Epoch 1/1\n",
      " - 24s - loss: 0.0057 - acc: 0.2431 - val_loss: 0.0101 - val_acc: 0.1723\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',patience=3, min_lr=0.00001,factor=0.1)\n",
    "for i in range(40):\n",
    "    model.fit(X_train, Y_train,\n",
    "              epochs=1,\n",
    "              batch_size=batch_size,\n",
    "              verbose=2,\n",
    "              validation_data = (X_test, Y_test))\n",
    "    model.reset_states()\n",
    "\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# model.fit(X_train, Y_train,\n",
    "#           epochs=50,\n",
    "#           batch_size=batch_size,\n",
    "#           verbose=2,\n",
    "#           callbacks=[reduce_lr],\n",
    "#           validation_data = (X_test, Y_test))\n",
    "\n",
    "# Save the weights\n",
    "model.save_weights('model_weights.h5')\n",
    "\n",
    "# Save the model architecture\n",
    "with open('model_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model reconstruction from JSON file\n",
    "with open('model_architecture.json', 'r') as f:\n",
    "    model = model_from_json(f.read())\n",
    "\n",
    "# Load weights into the new model\n",
    "model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrying out Prediction on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(0,len(X_test)):\n",
    "    pred = model.predict(X_test[i:(i+1),:,:])\n",
    "    y_pred.append(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renormalizing and seasonalizing the predictions and true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: Series.strides is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "season_high  = pd.DataFrame(rolling_window(stl_high.seasonal.iloc[:,0][in_win:len(stl_high.seasonal)], out_win, 1))\n",
    "season_low   = pd.DataFrame(rolling_window(stl_low.seasonal.iloc[:,0][in_win:len(stl_low.seasonal)], out_win, 1))\n",
    "season_close = pd.DataFrame(rolling_window(stl_close.seasonal.iloc[:,0][in_win:len(stl_close.seasonal)], out_win, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: Series.strides is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "season_high_pr  = pd.DataFrame(rolling_window(stl_high.seasonal.iloc[:,0][0:(len(stl_high.seasonal)-out_win)], in_win, 1))\n",
    "season_high_pr.drop(season_high_pr.columns[0:(in_win-out_win)], axis=1, inplace=True)\n",
    "season_high_pr.columns = np.arange(len(season_high_pr.columns))\n",
    "season_low_pr   = pd.DataFrame(rolling_window(stl_low.seasonal.iloc[:,0][0:(len(stl_low.seasonal)-out_win)], in_win, 1))\n",
    "season_low_pr.drop(season_low_pr.columns[0:(in_win-out_win)], axis=1, inplace=True)\n",
    "season_low_pr.columns = np.arange(len(season_low_pr.columns))\n",
    "season_close_pr = pd.DataFrame(rolling_window(stl_close.seasonal.iloc[:,0][0:(len(stl_close.seasonal)-out_win)], in_win, 1))\n",
    "season_close_pr.drop(season_close_pr.columns[0:(in_win-out_win)], axis=1, inplace=True)\n",
    "season_close_pr.columns = np.arange(len(season_close_pr.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1551"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383, 12)\n",
      "(383, 12)\n",
      "(383, 12)\n"
     ]
    }
   ],
   "source": [
    "#high_pred  = pd.DataFrame(y_pred[:,:,0])\n",
    "#low_pred   = pd.DataFrame(y_pred[:,:,1])\n",
    "close_pred = pd.DataFrame(y_pred[:,])\n",
    "print(close_pred.shape)\n",
    "#high_denorm_pred  = high_pred.add(data_high_win_in.iloc[X_train.shape[0]:,out_win-1].reset_index(drop=True), axis='index')\n",
    "#low_denorm_pred   = low_pred.add(data_low_win_in.iloc[X_train.shape[0]:,out_win-1].reset_index(drop=True), axis='index')\n",
    "close_denorm_pred = close_pred.add(data_close_win_in.iloc[X_train.shape[0]:,out_win-1].reset_index(drop=True), axis='index')\n",
    "print(close_denorm_pred.shape)\n",
    "#deseason_high_pred  = high_denorm_pred.add(season_high_pr.iloc[X_train.shape[0]:,].reset_index(drop=True), axis='index')\n",
    "#deseason_low_pred   = low_denorm_pred.add(season_low_pr.iloc[X_train.shape[0]:,].reset_index(drop=True), axis='index')\n",
    "deseason_close_pred = close_denorm_pred.add(season_close_pr.iloc[X_train.shape[0]:,].reset_index(drop=True), axis='index')\n",
    "print(deseason_close_pred.shape)\n",
    "#pred_high  = np.exp(deseason_high_pred)\n",
    "#pred_low   = np.exp(deseason_low_pred)\n",
    "pred_close = np.exp(deseason_close_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4374.793790</td>\n",
       "      <td>4465.549247</td>\n",
       "      <td>4402.686640</td>\n",
       "      <td>4383.525484</td>\n",
       "      <td>4285.779348</td>\n",
       "      <td>4394.703740</td>\n",
       "      <td>4605.852640</td>\n",
       "      <td>4457.998286</td>\n",
       "      <td>4438.393867</td>\n",
       "      <td>4487.992572</td>\n",
       "      <td>4522.759326</td>\n",
       "      <td>4507.631432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4109.871391</td>\n",
       "      <td>4153.873394</td>\n",
       "      <td>4210.278911</td>\n",
       "      <td>4137.852812</td>\n",
       "      <td>4180.057559</td>\n",
       "      <td>4076.374341</td>\n",
       "      <td>3962.872918</td>\n",
       "      <td>3939.722726</td>\n",
       "      <td>3871.764142</td>\n",
       "      <td>3906.317787</td>\n",
       "      <td>3847.893243</td>\n",
       "      <td>3892.889186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4136.902510</td>\n",
       "      <td>4224.764186</td>\n",
       "      <td>4186.168798</td>\n",
       "      <td>4235.007012</td>\n",
       "      <td>4197.519580</td>\n",
       "      <td>4177.739026</td>\n",
       "      <td>4209.242339</td>\n",
       "      <td>4165.485387</td>\n",
       "      <td>4220.254411</td>\n",
       "      <td>4278.610474</td>\n",
       "      <td>4279.455037</td>\n",
       "      <td>4330.235568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4309.731383</td>\n",
       "      <td>4318.179514</td>\n",
       "      <td>4343.708727</td>\n",
       "      <td>4375.463060</td>\n",
       "      <td>4349.500257</td>\n",
       "      <td>4293.791129</td>\n",
       "      <td>4256.428008</td>\n",
       "      <td>4274.013375</td>\n",
       "      <td>4264.739306</td>\n",
       "      <td>4291.201455</td>\n",
       "      <td>4322.648775</td>\n",
       "      <td>4302.031697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4385.603275</td>\n",
       "      <td>4429.187255</td>\n",
       "      <td>4363.531167</td>\n",
       "      <td>4269.472711</td>\n",
       "      <td>4132.911513</td>\n",
       "      <td>4115.480135</td>\n",
       "      <td>4187.991330</td>\n",
       "      <td>4170.336392</td>\n",
       "      <td>4204.299295</td>\n",
       "      <td>4270.725687</td>\n",
       "      <td>4251.237723</td>\n",
       "      <td>4185.008495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0            1            2            3            4   \\\n",
       "0  4374.793790  4465.549247  4402.686640  4383.525484  4285.779348   \n",
       "1  4109.871391  4153.873394  4210.278911  4137.852812  4180.057559   \n",
       "2  4136.902510  4224.764186  4186.168798  4235.007012  4197.519580   \n",
       "3  4309.731383  4318.179514  4343.708727  4375.463060  4349.500257   \n",
       "4  4385.603275  4429.187255  4363.531167  4269.472711  4132.911513   \n",
       "\n",
       "            5            6            7            8            9   \\\n",
       "0  4394.703740  4605.852640  4457.998286  4438.393867  4487.992572   \n",
       "1  4076.374341  3962.872918  3939.722726  3871.764142  3906.317787   \n",
       "2  4177.739026  4209.242339  4165.485387  4220.254411  4278.610474   \n",
       "3  4293.791129  4256.428008  4274.013375  4264.739306  4291.201455   \n",
       "4  4115.480135  4187.991330  4170.336392  4204.299295  4270.725687   \n",
       "\n",
       "            10           11  \n",
       "0  4522.759326  4507.631432  \n",
       "1  3847.893243  3892.889186  \n",
       "2  4279.455037  4330.235568  \n",
       "3  4322.648775  4302.031697  \n",
       "4  4251.237723  4185.008495  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_close.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high_test  = pd.DataFrame(y_test[:,:,0])\n",
    "#low_test   = pd.DataFrame(y_test[:,:,1])\n",
    "close_test = pd.DataFrame(Y_test[:,])\n",
    "\n",
    "#high_denorm_test  = high_test.add(data_high_win_in.iloc[X_train.shape[0]:,out_win-1].reset_index(drop=True), axis='index')\n",
    "#low_denorm_test   = low_test.add(data_low_win_in.iloc[X_train.shape[0]:,out_win-1].reset_index(drop=True), axis='index')\n",
    "close_denorm_test = close_test.add(data_close_win_in.iloc[X_train.shape[0]:,out_win-1].reset_index(drop=True), axis='index')\n",
    "\n",
    "#deseason_high_test  = high_denorm_test.add(season_high.iloc[X_train.shape[0]:,].reset_index(drop=True))\n",
    "#deseason_low_test   = low_denorm_test.add(season_low.iloc[X_train.shape[0]:,].reset_index(drop=True))\n",
    "deseason_close_test = close_denorm_test.add(season_close.iloc[X_train.shape[0]:,].reset_index(drop=True))\n",
    "\n",
    "#test_high  = np.exp(deseason_high_test)\n",
    "#test_low   = np.exp(deseason_low_test)\n",
    "test_close = np.exp(deseason_close_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 12)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: Series.strides is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#X_test[1,:,1]\n",
    "date_col_win_test = rolling_window(date_col[0:(len(data_bt)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "date_col_win_test = pd.DataFrame(date_col_win_test)\n",
    "\n",
    "data_open_win_test = rolling_window(data_open[0:(len(data_open)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "data_open_win_test = pd.DataFrame(data_open_win_test) \n",
    "\n",
    "data_high_win_test = rolling_window(data_high[0:(len(data_high)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "data_high_win_test = pd.DataFrame(data_high_win_test) \n",
    "\n",
    "\n",
    "data_low_win_test = rolling_window(data_low[0:(len(data_low)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "data_low_win_test = pd.DataFrame(data_low_win_test) \n",
    "\n",
    "\n",
    "data_close_win_test = rolling_window(data_close[0:(len(data_close)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "data_close_win_test = pd.DataFrame(data_close_win_test) \n",
    "\n",
    "\n",
    "data_vol_win_test = rolling_window(data_vol[0:(len(data_vol)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "data_vol_win_test = pd.DataFrame(data_vol_win_test) \n",
    "\n",
    "\n",
    "data_mark_win_test = rolling_window(data_mark[0:(len(data_mark)-out_win)], in_win, 1)[X_train.shape[0]:]\n",
    "data_mark_win_test = pd.DataFrame(data_mark_win_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 12)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_col_win_pred = pd.DataFrame(date_col_win_out[X_train.shape[0]:])\n",
    "date_col_win_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(383, 15)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(data_high_win_test))\n",
    "data_high_win_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-23 23:59:59</td>\n",
       "      <td>2017-08-24 23:59:58</td>\n",
       "      <td>2017-08-25 23:59:58</td>\n",
       "      <td>2017-08-26 23:59:51</td>\n",
       "      <td>2017-08-27 23:59:48</td>\n",
       "      <td>2017-08-28 23:59:58</td>\n",
       "      <td>2017-08-29 23:59:54</td>\n",
       "      <td>2017-08-30 23:59:59</td>\n",
       "      <td>2017-08-31 23:59:47</td>\n",
       "      <td>2017-09-01 23:59:54</td>\n",
       "      <td>2017-09-02 23:59:59</td>\n",
       "      <td>2017-09-03 23:59:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-24 23:59:58</td>\n",
       "      <td>2017-08-25 23:59:58</td>\n",
       "      <td>2017-08-26 23:59:51</td>\n",
       "      <td>2017-08-27 23:59:48</td>\n",
       "      <td>2017-08-28 23:59:58</td>\n",
       "      <td>2017-08-29 23:59:54</td>\n",
       "      <td>2017-08-30 23:59:59</td>\n",
       "      <td>2017-08-31 23:59:47</td>\n",
       "      <td>2017-09-01 23:59:54</td>\n",
       "      <td>2017-09-02 23:59:59</td>\n",
       "      <td>2017-09-03 23:59:57</td>\n",
       "      <td>2017-09-04 23:59:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-25 23:59:58</td>\n",
       "      <td>2017-08-26 23:59:51</td>\n",
       "      <td>2017-08-27 23:59:48</td>\n",
       "      <td>2017-08-28 23:59:58</td>\n",
       "      <td>2017-08-29 23:59:54</td>\n",
       "      <td>2017-08-30 23:59:59</td>\n",
       "      <td>2017-08-31 23:59:47</td>\n",
       "      <td>2017-09-01 23:59:54</td>\n",
       "      <td>2017-09-02 23:59:59</td>\n",
       "      <td>2017-09-03 23:59:57</td>\n",
       "      <td>2017-09-04 23:59:58</td>\n",
       "      <td>2017-09-05 23:59:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-26 23:59:51</td>\n",
       "      <td>2017-08-27 23:59:48</td>\n",
       "      <td>2017-08-28 23:59:58</td>\n",
       "      <td>2017-08-29 23:59:54</td>\n",
       "      <td>2017-08-30 23:59:59</td>\n",
       "      <td>2017-08-31 23:59:47</td>\n",
       "      <td>2017-09-01 23:59:54</td>\n",
       "      <td>2017-09-02 23:59:59</td>\n",
       "      <td>2017-09-03 23:59:57</td>\n",
       "      <td>2017-09-04 23:59:58</td>\n",
       "      <td>2017-09-05 23:59:52</td>\n",
       "      <td>2017-09-06 23:59:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-27 23:59:48</td>\n",
       "      <td>2017-08-28 23:59:58</td>\n",
       "      <td>2017-08-29 23:59:54</td>\n",
       "      <td>2017-08-30 23:59:59</td>\n",
       "      <td>2017-08-31 23:59:47</td>\n",
       "      <td>2017-09-01 23:59:54</td>\n",
       "      <td>2017-09-02 23:59:59</td>\n",
       "      <td>2017-09-03 23:59:57</td>\n",
       "      <td>2017-09-04 23:59:58</td>\n",
       "      <td>2017-09-05 23:59:52</td>\n",
       "      <td>2017-09-06 23:59:47</td>\n",
       "      <td>2017-09-07 23:59:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0                   1                   2   \\\n",
       "0 2017-08-23 23:59:59 2017-08-24 23:59:58 2017-08-25 23:59:58   \n",
       "1 2017-08-24 23:59:58 2017-08-25 23:59:58 2017-08-26 23:59:51   \n",
       "2 2017-08-25 23:59:58 2017-08-26 23:59:51 2017-08-27 23:59:48   \n",
       "3 2017-08-26 23:59:51 2017-08-27 23:59:48 2017-08-28 23:59:58   \n",
       "4 2017-08-27 23:59:48 2017-08-28 23:59:58 2017-08-29 23:59:54   \n",
       "\n",
       "                   3                   4                   5   \\\n",
       "0 2017-08-26 23:59:51 2017-08-27 23:59:48 2017-08-28 23:59:58   \n",
       "1 2017-08-27 23:59:48 2017-08-28 23:59:58 2017-08-29 23:59:54   \n",
       "2 2017-08-28 23:59:58 2017-08-29 23:59:54 2017-08-30 23:59:59   \n",
       "3 2017-08-29 23:59:54 2017-08-30 23:59:59 2017-08-31 23:59:47   \n",
       "4 2017-08-30 23:59:59 2017-08-31 23:59:47 2017-09-01 23:59:54   \n",
       "\n",
       "                   6                   7                   8   \\\n",
       "0 2017-08-29 23:59:54 2017-08-30 23:59:59 2017-08-31 23:59:47   \n",
       "1 2017-08-30 23:59:59 2017-08-31 23:59:47 2017-09-01 23:59:54   \n",
       "2 2017-08-31 23:59:47 2017-09-01 23:59:54 2017-09-02 23:59:59   \n",
       "3 2017-09-01 23:59:54 2017-09-02 23:59:59 2017-09-03 23:59:57   \n",
       "4 2017-09-02 23:59:59 2017-09-03 23:59:57 2017-09-04 23:59:58   \n",
       "\n",
       "                   9                   10                  11  \n",
       "0 2017-09-01 23:59:54 2017-09-02 23:59:59 2017-09-03 23:59:57  \n",
       "1 2017-09-02 23:59:59 2017-09-03 23:59:57 2017-09-04 23:59:58  \n",
       "2 2017-09-03 23:59:57 2017-09-04 23:59:58 2017-09-05 23:59:52  \n",
       "3 2017-09-04 23:59:58 2017-09-05 23:59:52 2017-09-06 23:59:47  \n",
       "4 2017-09-05 23:59:52 2017-09-06 23:59:47 2017-09-07 23:59:56  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_col_win_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "for index,row in pred_close.iterrows():\n",
    "    plt.figure()\n",
    "    plt.plot(date_col_win_pred.iloc[index,:],pred_close.iloc[index,:],color='r',marker = '.')\n",
    "    plt.plot(date_col_win_test.iloc[index,:],data_close_win_test.iloc[index,:],color='g',marker = '.')\n",
    "    plt.plot(date_col_win_pred.iloc[index,:],test_close.iloc[index,:],color='b',marker = '.')\n",
    "    if index == 25:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "error_high = []\n",
    "error_low = []\n",
    "error_close = []\n",
    "\n",
    "# for index,row in pred_high.iterrows():\n",
    "#     error_high.append(smape(test_high.iloc[index,:], pred_high.iloc[index,:]))\n",
    "\n",
    "# for index,row in pred_low.iterrows():\n",
    "#     error_low.append(smape(test_low.iloc[index,:], pred_low.iloc[index,:]))\n",
    "    \n",
    "for index,row in pred_close.iterrows():\n",
    "    error_close.append(smape(test_close.iloc[index,:], pred_close.iloc[index,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMAPE ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close prediciton SMAPE score :  9.594184534156367\n"
     ]
    }
   ],
   "source": [
    "# print(\"High prediciton SMAPE score : \",sum(error_high)/len(error_high))\n",
    "# print(\"Low prediciton SMAPE score : \",sum(error_low)/len(error_low))\n",
    "print(\"Close prediciton SMAPE score : \",sum(error_close)/len(error_close))\n",
    "#print(\"Overall SMAPE score : \",((sum(error_high)/len(error_high)) + (sum(error_low)/len(error_low)) + (sum(error_close)/len(error_close)))/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_pred_check = data_close_win_test.iloc[:,in_win-1]-pred_close.iloc[:,0]\n",
    "close_true_check = data_close_win_test.iloc[:,in_win-1]-test_close.iloc[:,0]\n",
    "\n",
    "# high_pred_check = data_high_win_test.iloc[:,in_win-1]-pred_high.iloc[:,0]\n",
    "# high_true_check = data_high_win_test.iloc[:,in_win-1]-test_high.iloc[:,0]\n",
    "\n",
    "# low_pred_check = data_low_win_test.iloc[:,in_win-1]-pred_low.iloc[:,0]\n",
    "# low_true_check = data_low_win_test.iloc[:,in_win-1]-test_low.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-Score , Precision Recall, True Positive Rate & True Negative Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_tp = 0\n",
    "close_tn = 0\n",
    "close_fp = 0\n",
    "close_fn = 0\n",
    "\n",
    "# high_tp = 0\n",
    "# high_tn = 0\n",
    "# high_fp = 0\n",
    "# high_fn = 0\n",
    "\n",
    "# low_tp = 0\n",
    "# low_tn = 0\n",
    "# low_fp = 0\n",
    "# low_fn = 0\n",
    "for i in range(0,len(close_pred_check)):\n",
    "    if(close_true_check[i] >= 0  and close_pred_check[i] >= 0):\n",
    "        close_tp += 1\n",
    "    if(close_true_check[i] >= 0  and close_pred_check[i] < 0):\n",
    "        close_tn += 1 \n",
    "    if(close_true_check[i] < 0  and close_pred_check[i] < 0):\n",
    "        close_fp += 1\n",
    "    if(close_true_check[i] < 0  and close_pred_check[i] >= 0):\n",
    "        close_fn += 1\n",
    "\n",
    "#     if(high_true_check[i] >= 0  and high_pred_check[i] >= 0):\n",
    "#         high_tp += 1\n",
    "#     if(high_true_check[i] >= 0  and high_pred_check[i] < 0):\n",
    "#         high_tn += 1 \n",
    "#     if(high_true_check[i] < 0  and high_pred_check[i] < 0):\n",
    "#         high_fp += 1\n",
    "#     if(high_true_check[i] < 0  and high_pred_check[i] >= 0):\n",
    "#         high_fn += 1\n",
    "    \n",
    "#     if(low_true_check[i] >= 0  and low_pred_check[i] >= 0):\n",
    "#         low_tp += 1\n",
    "#     if(low_true_check[i] >= 0  and low_pred_check[i] < 0):\n",
    "#         low_tn += 1 \n",
    "#     if(low_true_check[i] < 0  and low_pred_check[i] < 0):\n",
    "#         low_fp += 1\n",
    "#     if(low_true_check[i] < 0  and low_pred_check[i] >= 0):\n",
    "#         low_fn += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(tp,fp):\n",
    "    return(tp/(tp + fp))\n",
    "\n",
    "def recall(tp,fn):\n",
    "    return(tp/(tp + fn))\n",
    "\n",
    "def f_score(precision,recall):\n",
    "    return(2*((precision * recall)/(precision + recall)))\n",
    "\n",
    "def tp_rate(tp,fn):\n",
    "    return(tp/(tp+fn))\n",
    "\n",
    "def fp_rate(fp,tn):\n",
    "    return(fp/(fp+tn))\n",
    "\n",
    "def Accuracy(TP,TN,FP,FN):\n",
    "    return (TP + TN) / (TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close precision :  [0.42857142857142855, 0.5104166666666666]\n",
      "close recall    :  [0.7235294117647059, 0.2300469483568075]\n",
      "close f_score   :  [0.5382932166301969, 0.3171521035598705]\n",
      "close tp_rate   :  [0.7235294117647059, 0.2300469483568075]\n",
      "close fp_rate   :  [0.7699530516431925, 0.27647058823529413]\n",
      "close Accuracy  :  [0.4490861618798956, 0.4490861618798956]\n"
     ]
    }
   ],
   "source": [
    "close_precision  = [precision(close_tp,close_fp) , precision(close_tn,close_fn)]\n",
    "close_recall     = [recall(close_tp,close_fn) , recall(close_tn,close_fp)]\n",
    "close_f_score    = [f_score(close_precision[0],close_recall[0]) , f_score(close_precision[1],close_recall[1])]\n",
    "close_tp_rate    = [tp_rate(close_tp,close_fn), tp_rate(close_tn,close_fp)]\n",
    "close_fp_rate    = [fp_rate(close_fp,close_tn) , fp_rate(close_fn,close_tp)]\n",
    "close_Accuracy   = [Accuracy(close_tp,close_tn,close_fp,close_fn), Accuracy(close_tn,close_tp,close_fn,close_fp)]\n",
    "\n",
    "print(\"close precision : \",close_precision)\n",
    "print(\"close recall    : \",close_recall)\n",
    "print(\"close f_score   : \",close_f_score)\n",
    "print(\"close tp_rate   : \",close_tp_rate)\n",
    "print(\"close fp_rate   : \",close_fp_rate)\n",
    "print(\"close Accuracy  : \",close_Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_precision  = [precision(high_tp,high_fp) , precision(high_tn,high_fn)]\n",
    "# high_recall     = [recall(high_tp,high_fn) , recall(high_tn,high_fp)]\n",
    "# high_f_score    = [f_score(high_precision[0],high_recall[0]) , f_score(high_precision[1],high_recall[1])]\n",
    "# high_tp_rate    = [tp_rate(high_tp,high_fn), tp_rate(high_tn,high_fp)]\n",
    "# high_fp_rate    = [fp_rate(high_fp,high_tn) , fp_rate(high_fn,high_tp)]\n",
    "# high_Accuracy   = [Accuracy(high_tp,high_tn,high_fp,high_fn), Accuracy(high_tn,high_tp,high_fn,high_fp)]\n",
    "\n",
    "# print(\"high precision : \",high_precision)\n",
    "# print(\"high recall    : \",high_recall)\n",
    "# print(\"high f_score   : \",high_f_score)\n",
    "# print(\"high tp_rate   : \",high_tp_rate)\n",
    "# print(\"high fp_rate   : \",high_fp_rate)\n",
    "# print(\"high Accuracy  : \",high_Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_precision  = [precision(low_tp,low_fp) , precision(low_tn,low_fn)]\n",
    "# low_recall     = [recall(low_tp,low_fn) , recall(low_tn,low_fp)]\n",
    "# low_f_score    = [f_score(low_precision[0],low_recall[0]) , f_score(low_precision[1],low_recall[1])]\n",
    "# low_tp_rate    = [tp_rate(low_tp,low_fn), tp_rate(low_tn,low_fp)]\n",
    "# low_fp_rate    = [fp_rate(low_fp,low_tn) , fp_rate(low_fn,low_tp)]\n",
    "# low_Accuracy   = [Accuracy(low_tp,low_tn,low_fp,low_fn), Accuracy(low_tn,low_tp,low_fn,low_fp)]\n",
    "\n",
    "# print(\"low precision : \",low_precision)\n",
    "# print(\"low recall    : \",low_recall)\n",
    "# print(\"low f_score   : \",low_f_score)\n",
    "# print(\"low tp_rate   : \",low_tp_rate)\n",
    "# print(\"low fp_rate   : \",low_fp_rate)\n",
    "# print(\"low Accuracy ,: \",low_Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
